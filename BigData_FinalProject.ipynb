{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BigData_FinalProject.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Clasificación de imágenes pulmonares de rayos X mediante redes neuronales convolucionales"
      ],
      "metadata": {
        "id": "4zUnxum0rjUz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Autores:\n",
        "\n",
        "\n",
        "*   Alicia Portela Estévez\n",
        "*   Álvaro García López\n",
        "*   Álvaro Marínez Petit\n"
      ],
      "metadata": {
        "id": "tJBT2IQA3ESz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Introducción\n",
        "\n",
        "La neumonía es una infección que puede afectar a uno a ambos pulmones, causada tanto por virus como por hongos o bacterias. Según la OMS, en 2019 el número de fallecidos a causa de esta enfermedad fue de más de 2 millones de personas en todo el mundo, por lo que un diágnóstico temprano ayudaría a disminuir este número [[Ref.]](https://www.who.int/es/news-room/fact-sheets/detail/the-top-10-causes-of-death)\n",
        "\n",
        "En el trabajo final de la asignatura \"Ingeniería de Grandes Volúmenes de Datos\" pretendemos crear un modelo de \"Deep Learning\" basado en Redes Neuronales Convolucionales que sea capaz de distinguir entre imágenes pulmonares de rayos X procedentes de pacientes con y sin neumonía. De esta forma, podríamos desarrollar una herramienta informática que automatice con cierta calidad el diagnóstico temprano de estos casos.\n",
        "\n",
        "Dada la gran cantidad de datos que manejamos, hemos utilizado una solución basada en Apache Spark para llevar a cabo el entrenamiento de la red neuronal. De esta forma, el proceso se realiza de forma óptima."
      ],
      "metadata": {
        "id": "qbh121V63gQS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preparación del entorno de trabajo"
      ],
      "metadata": {
        "id": "8aG-zqWb3UUX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Instalar JAVA (jdk8)"
      ],
      "metadata": {
        "id": "yNJj2WyDVwSk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "32q3GakvTgMM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5990005a-21a6-44e9-9c23-519c57f555ba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/java to provide /usr/bin/java (java) in manual mode\n"
          ]
        }
      ],
      "source": [
        "# Instalamos jdk8\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "\n",
        "import os\n",
        "# Establecemos la ruta del entorno jdk para poder ejecutar Pyspark en Colab\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "!update-alternatives --set java /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/java\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Instalar Analytics Zoo"
      ],
      "metadata": {
        "id": "m9UhE-1bX-jO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Instalamos la última versión de Analytics Zoo\n",
        "# Mediante esta acción se instalan automáticamente pyspark, bigdl y sus dependencias.\n",
        "!pip install --pre --upgrade analytics-zoo[ray]\n",
        "exit()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5SsLhYMXUIAd",
        "outputId": "621fcd26-6055-484c-f0cb-495a68d38df2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting analytics-zoo[ray]\n",
            "  Downloading analytics_zoo-0.12.0b2022021001-py2.py3-none-manylinux1_x86_64.whl (194.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 194.7 MB 64 kB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from analytics-zoo[ray]) (3.4.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from analytics-zoo[ray]) (21.3)\n",
            "Collecting bigdl==0.13.1.dev0\n",
            "  Downloading BigDL-0.13.1.dev0-py2.py3-none-manylinux1_x86_64.whl (114.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 114.0 MB 29 kB/s \n",
            "\u001b[?25hCollecting conda-pack==0.3.1\n",
            "  Downloading conda_pack-0.3.1-py2.py3-none-any.whl (27 kB)\n",
            "Collecting pyspark==2.4.6\n",
            "  Downloading pyspark-2.4.6.tar.gz (218.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 218.4 MB 59 kB/s \n",
            "\u001b[?25hRequirement already satisfied: psutil in /usr/local/lib/python3.7/dist-packages (from analytics-zoo[ray]) (5.4.8)\n",
            "Collecting async-timeout==3.0.1\n",
            "  Downloading async_timeout-3.0.1-py3-none-any.whl (8.2 kB)\n",
            "Collecting setproctitle\n",
            "  Downloading setproctitle-1.2.2-cp37-cp37m-manylinux1_x86_64.whl (36 kB)\n",
            "Collecting aioredis==1.1.0\n",
            "  Downloading aioredis-1.1.0-py3-none-any.whl (65 kB)\n",
            "\u001b[K     |████████████████████████████████| 65 kB 4.4 MB/s \n",
            "\u001b[?25hCollecting ray==1.2.0\n",
            "  Downloading ray-1.2.0-cp37-cp37m-manylinux2014_x86_64.whl (47.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 47.5 MB 66.0 MB/s \n",
            "\u001b[?25hCollecting aiohttp==3.7.0\n",
            "  Downloading aiohttp-3.7.0-cp37-cp37m-manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3 MB 50.9 MB/s \n",
            "\u001b[?25hCollecting hiredis==1.1.0\n",
            "  Downloading hiredis-1.1.0-cp37-cp37m-manylinux2010_x86_64.whl (62 kB)\n",
            "\u001b[K     |████████████████████████████████| 62 kB 817 kB/s \n",
            "\u001b[?25hRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp==3.7.0->analytics-zoo[ray]) (21.4.0)\n",
            "Requirement already satisfied: chardet<4.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp==3.7.0->analytics-zoo[ray]) (3.0.4)\n",
            "Collecting yarl<2.0,>=1.0\n",
            "  Downloading yarl-1.7.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (271 kB)\n",
            "\u001b[K     |████████████████████████████████| 271 kB 61.4 MB/s \n",
            "\u001b[?25hCollecting multidict<7.0,>=4.5\n",
            "  Downloading multidict-6.0.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (94 kB)\n",
            "\u001b[K     |████████████████████████████████| 94 kB 2.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.7 in /usr/local/lib/python3.7/dist-packages (from bigdl==0.13.1.dev0->analytics-zoo[ray]) (1.19.5)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from bigdl==0.13.1.dev0->analytics-zoo[ray]) (1.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from conda-pack==0.3.1->analytics-zoo[ray]) (57.4.0)\n",
            "Collecting py4j==0.10.7\n",
            "  Downloading py4j-0.10.7-py2.py3-none-any.whl (197 kB)\n",
            "\u001b[K     |████████████████████████████████| 197 kB 55.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from ray==1.2.0->analytics-zoo[ray]) (3.13)\n",
            "Collecting colorful\n",
            "  Downloading colorful-0.6.0a1-py2.py3-none-any.whl (202 kB)\n",
            "\u001b[K     |████████████████████████████████| 202 kB 57.0 MB/s \n",
            "\u001b[?25hCollecting redis>=3.5.0\n",
            "  Downloading redis-4.1.3-py3-none-any.whl (173 kB)\n",
            "\u001b[K     |████████████████████████████████| 173 kB 59.1 MB/s \n",
            "\u001b[?25hCollecting colorama\n",
            "  Downloading colorama-0.4.4-py2.py3-none-any.whl (16 kB)\n",
            "Collecting gpustat\n",
            "  Downloading gpustat-1.0.0b1.tar.gz (82 kB)\n",
            "\u001b[K     |████████████████████████████████| 82 kB 265 kB/s \n",
            "\u001b[?25hRequirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from ray==1.2.0->analytics-zoo[ray]) (1.0.3)\n",
            "Collecting py-spy>=0.2.0\n",
            "  Downloading py_spy-0.4.0.dev1-py2.py3-none-manylinux1_x86_64.whl (3.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.0 MB 45.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: click>=7.0 in /usr/local/lib/python3.7/dist-packages (from ray==1.2.0->analytics-zoo[ray]) (7.1.2)\n",
            "Collecting opencensus\n",
            "  Downloading opencensus-0.8.0-py2.py3-none-any.whl (128 kB)\n",
            "\u001b[K     |████████████████████████████████| 128 kB 45.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from ray==1.2.0->analytics-zoo[ray]) (2.23.0)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.7/dist-packages (from ray==1.2.0->analytics-zoo[ray]) (3.17.3)\n",
            "Collecting aiohttp-cors\n",
            "  Downloading aiohttp_cors-0.7.0-py3-none-any.whl (27 kB)\n",
            "Requirement already satisfied: grpcio>=1.28.1 in /usr/local/lib/python3.7/dist-packages (from ray==1.2.0->analytics-zoo[ray]) (1.43.0)\n",
            "Requirement already satisfied: prometheus-client>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from ray==1.2.0->analytics-zoo[ray]) (0.13.1)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.7/dist-packages (from ray==1.2.0->analytics-zoo[ray]) (4.3.3)\n",
            "Collecting deprecated>=1.2.3\n",
            "  Downloading Deprecated-1.2.13-py2.py3-none-any.whl (9.6 kB)\n",
            "Requirement already satisfied: importlib-metadata>=1.0 in /usr/local/lib/python3.7/dist-packages (from redis>=3.5.0->ray==1.2.0->analytics-zoo[ray]) (4.10.1)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.7/dist-packages (from deprecated>=1.2.3->redis>=3.5.0->ray==1.2.0->analytics-zoo[ray]) (1.13.3)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=1.0->redis>=3.5.0->ray==1.2.0->analytics-zoo[ray]) (3.10.0.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=1.0->redis>=3.5.0->ray==1.2.0->analytics-zoo[ray]) (3.7.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->analytics-zoo[ray]) (3.0.7)\n",
            "Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.7/dist-packages (from yarl<2.0,>=1.0->aiohttp==3.7.0->analytics-zoo[ray]) (2.10)\n",
            "Requirement already satisfied: nvidia-ml-py3>=7.352.0 in /usr/local/lib/python3.7/dist-packages (from gpustat->ray==1.2.0->analytics-zoo[ray]) (7.352.0)\n",
            "Collecting blessed>=1.17.1\n",
            "  Downloading blessed-1.19.1-py2.py3-none-any.whl (58 kB)\n",
            "\u001b[K     |████████████████████████████████| 58 kB 5.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: wcwidth>=0.1.4 in /usr/local/lib/python3.7/dist-packages (from blessed>=1.17.1->gpustat->ray==1.2.0->analytics-zoo[ray]) (0.2.5)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema->ray==1.2.0->analytics-zoo[ray]) (0.18.1)\n",
            "Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema->ray==1.2.0->analytics-zoo[ray]) (5.4.0)\n",
            "Collecting opencensus-context==0.1.2\n",
            "  Downloading opencensus_context-0.1.2-py2.py3-none-any.whl (4.4 kB)\n",
            "Requirement already satisfied: google-api-core<3.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from opencensus->ray==1.2.0->analytics-zoo[ray]) (1.26.3)\n",
            "Requirement already satisfied: google-auth<2.0dev,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3.0.0,>=1.0.0->opencensus->ray==1.2.0->analytics-zoo[ray]) (1.35.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3.0.0,>=1.0.0->opencensus->ray==1.2.0->analytics-zoo[ray]) (1.54.0)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from google-api-core<3.0.0,>=1.0.0->opencensus->ray==1.2.0->analytics-zoo[ray]) (2018.9)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2.0dev,>=1.21.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray==1.2.0->analytics-zoo[ray]) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2.0dev,>=1.21.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray==1.2.0->analytics-zoo[ray]) (4.2.4)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<2.0dev,>=1.21.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray==1.2.0->analytics-zoo[ray]) (4.8)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2.0dev,>=1.21.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray==1.2.0->analytics-zoo[ray]) (0.4.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->ray==1.2.0->analytics-zoo[ray]) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->ray==1.2.0->analytics-zoo[ray]) (1.24.3)\n",
            "Building wheels for collected packages: pyspark, gpustat\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-2.4.6-py2.py3-none-any.whl size=218814407 sha256=3f02cc2acff6ed44105053f36f1062526b2001b7eee985f698d1735ace01e563\n",
            "  Stored in directory: /root/.cache/pip/wheels/f1/42/b0/ba397759613f4feb1611021a2503e60e344e546671b2ae04f8\n",
            "  Building wheel for gpustat (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gpustat: filename=gpustat-1.0.0b1-py3-none-any.whl size=15979 sha256=1cb5d622d36f6fcb94fea42f07337a3a08b5363f952dbc671dd59861ce8ee901\n",
            "  Stored in directory: /root/.cache/pip/wheels/1a/16/e2/3e2437fba4c4b6a97a97bd96fce5d14e66cff5c4966fb1cc8c\n",
            "Successfully built pyspark gpustat\n",
            "Installing collected packages: multidict, yarl, py4j, async-timeout, pyspark, opencensus-context, hiredis, deprecated, blessed, aiohttp, redis, py-spy, opencensus, gpustat, conda-pack, colorful, colorama, bigdl, aioredis, aiohttp-cors, setproctitle, ray, analytics-zoo\n",
            "Successfully installed aiohttp-3.7.0 aiohttp-cors-0.7.0 aioredis-1.1.0 analytics-zoo-0.12.0b2022021001 async-timeout-3.0.1 bigdl-0.13.1.dev0 blessed-1.19.1 colorama-0.4.4 colorful-0.6.0a1 conda-pack-0.3.1 deprecated-1.2.13 gpustat-1.0.0b1 hiredis-1.1.0 multidict-6.0.2 opencensus-0.8.0 opencensus-context-0.1.2 py-spy-0.4.0.dev1 py4j-0.10.7 pyspark-2.4.6 ray-1.2.0 redis-4.1.3 setproctitle-1.2.2 yarl-1.7.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importamos Orca"
      ],
      "metadata": {
        "id": "Jrv080saazz_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importamos las librerías y módulos necesarios\n",
        "from zoo.orca import init_orca_context, stop_orca_context\n",
        "from zoo.orca import OrcaContext\n",
        "\n",
        "# Fijando este parámetro a 'True' se muestra en el terminal del Jupyter Notebook el stdout y el stderr\n",
        "OrcaContext.log_output = True\n",
        "\n",
        "# Iniciamos el contexto Orca\n",
        "init_orca_context(cluster_mode=\"local\", cores=1)\n",
        "\n",
        "# Obtenemos la sesión de spark iniciada por Orca\n",
        "spark = OrcaContext.get_spark_session()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qe38Kp5vVnN-",
        "outputId": "71e1b11f-a77b-49ba-8fa3-d32267aadd9b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initializing orca context\n",
            "Current pyspark location is : /usr/local/lib/python3.7/dist-packages/pyspark/__init__.py\n",
            "Start to getOrCreate SparkContext\n",
            "pyspark_submit_args is:  --driver-class-path /usr/local/lib/python3.7/dist-packages/zoo/share/lib/analytics-zoo-bigdl_0.13.1-SNAPSHOT-spark_2.4.6-0.12.0-SNAPSHOT-jar-with-dependencies.jar:/usr/local/lib/python3.7/dist-packages/bigdl/share/lib/bigdl-0.13.1-SNAPSHOT-jar-with-dependencies.jar pyspark-shell \n",
            "2022-02-10 11:26:07 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting default log level to \"WARN\".\n",
            "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
            "\n",
            "User settings:\n",
            "\n",
            "   KMP_AFFINITY=granularity=fine,compact,1,0\n",
            "   KMP_BLOCKTIME=0\n",
            "   KMP_SETTINGS=1\n",
            "   OMP_NUM_THREADS=1\n",
            "\n",
            "Effective settings:\n",
            "\n",
            "   KMP_ABORT_DELAY=0\n",
            "   KMP_ADAPTIVE_LOCK_PROPS='1,1024'\n",
            "   KMP_ALIGN_ALLOC=64\n",
            "   KMP_ALL_THREADPRIVATE=128\n",
            "   KMP_ATOMIC_MODE=2\n",
            "   KMP_BLOCKTIME=0\n",
            "   KMP_CPUINFO_FILE: value is not defined\n",
            "   KMP_DETERMINISTIC_REDUCTION=false\n",
            "   KMP_DEVICE_THREAD_LIMIT=2147483647\n",
            "   KMP_DISP_HAND_THREAD=false\n",
            "   KMP_DISP_NUM_BUFFERS=7\n",
            "   KMP_DUPLICATE_LIB_OK=false\n",
            "   KMP_FORCE_REDUCTION: value is not defined\n",
            "   KMP_FOREIGN_THREADS_THREADPRIVATE=true\n",
            "   KMP_FORKJOIN_BARRIER='2,2'\n",
            "   KMP_FORKJOIN_BARRIER_PATTERN='hyper,hyper'\n",
            "   KMP_FORKJOIN_FRAMES=true\n",
            "   KMP_FORKJOIN_FRAMES_MODE=3\n",
            "   KMP_GTID_MODE=3\n",
            "   KMP_HANDLE_SIGNALS=false\n",
            "   KMP_HOT_TEAMS_MAX_LEVEL=1\n",
            "   KMP_HOT_TEAMS_MODE=0\n",
            "   KMP_INIT_AT_FORK=true\n",
            "   KMP_ITT_PREPARE_DELAY=0\n",
            "   KMP_LIBRARY=throughput\n",
            "   KMP_LOCK_KIND=queuing\n",
            "   KMP_MALLOC_POOL_INCR=1M\n",
            "   KMP_MWAIT_HINTS=0\n",
            "   KMP_NUM_LOCKS_IN_BLOCK=1\n",
            "   KMP_PLAIN_BARRIER='2,2'\n",
            "   KMP_PLAIN_BARRIER_PATTERN='hyper,hyper'\n",
            "   KMP_REDUCTION_BARRIER='1,1'\n",
            "   KMP_REDUCTION_BARRIER_PATTERN='hyper,hyper'\n",
            "   KMP_SCHEDULE='static,balanced;guided,iterative'\n",
            "   KMP_SETTINGS=true\n",
            "   KMP_SPIN_BACKOFF_PARAMS='4096,100'\n",
            "   KMP_STACKOFFSET=64\n",
            "   KMP_STACKPAD=0\n",
            "   KMP_STACKSIZE=8M\n",
            "   KMP_STORAGE_MAP=false\n",
            "   KMP_TASKING=2\n",
            "   KMP_TASKLOOP_MIN_TASKS=0\n",
            "   KMP_TASK_STEALING_CONSTRAINT=1\n",
            "   KMP_TEAMS_THREAD_LIMIT=2\n",
            "   KMP_TOPOLOGY_METHOD=all\n",
            "   KMP_USER_LEVEL_MWAIT=false\n",
            "   KMP_USE_YIELD=1\n",
            "   KMP_VERSION=false\n",
            "   KMP_WARNINGS=true\n",
            "   OMP_AFFINITY_FORMAT='OMP: pid %P tid %i thread %n bound to OS proc set {%A}'\n",
            "   OMP_ALLOCATOR=omp_default_mem_alloc\n",
            "   OMP_CANCELLATION=false\n",
            "   OMP_DEBUG=disabled\n",
            "   OMP_DEFAULT_DEVICE=0\n",
            "   OMP_DISPLAY_AFFINITY=false\n",
            "   OMP_DISPLAY_ENV=false\n",
            "   OMP_DYNAMIC=false\n",
            "   OMP_MAX_ACTIVE_LEVELS=2147483647\n",
            "   OMP_MAX_TASK_PRIORITY=0\n",
            "   OMP_NESTED=false\n",
            "   OMP_NUM_THREADS='1'\n",
            "   OMP_PLACES: value is not defined\n",
            "   OMP_PROC_BIND='intel'\n",
            "   OMP_SCHEDULE='static'\n",
            "   OMP_STACKSIZE=8M\n",
            "   OMP_TARGET_OFFLOAD=DEFAULT\n",
            "   OMP_THREAD_LIMIT=2147483647\n",
            "   OMP_TOOL=enabled\n",
            "   OMP_TOOL_LIBRARIES: value is not defined\n",
            "   OMP_WAIT_POLICY=PASSIVE\n",
            "   KMP_AFFINITY='noverbose,warnings,respect,granularity=fine,compact,1,0'\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cls.getname: com.intel.analytics.bigdl.python.api.Sample\n",
            "BigDLBasePickler registering: bigdl.util.common  Sample\n",
            "cls.getname: com.intel.analytics.bigdl.python.api.EvaluatedResult\n",
            "BigDLBasePickler registering: bigdl.util.common  EvaluatedResult\n",
            "cls.getname: com.intel.analytics.bigdl.python.api.JTensor\n",
            "BigDLBasePickler registering: bigdl.util.common  JTensor\n",
            "cls.getname: com.intel.analytics.bigdl.python.api.JActivity\n",
            "BigDLBasePickler registering: bigdl.util.common  JActivity\n",
            "Successfully got a SparkContext\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importamos otras librerías y módulos necesarios"
      ],
      "metadata": {
        "id": "NlbcfiLb-MAr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ],
      "metadata": {
        "id": "paMlKrjV-hzK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Comprobamos la versión instalada de TensorFlow y Keras"
      ],
      "metadata": {
        "id": "mhI1dZAo_6Vb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf.__version__"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "1zpY58Oo_1MY",
        "outputId": "6d9d4b92-876d-4f8e-bc89-6437522773d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2.7.0'"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "keras.__version__"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "nb48P804_3pD",
        "outputId": "38a9c9b1-5541-4252-eee7-42db6140c7b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2.7.0'"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importación de los datos y creación del modelo"
      ],
      "metadata": {
        "id": "BnpvQwfL-hzJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Definimos tres funciones que serán llamadas posteriormente en el modelo, cuya finalidad es cargar los datos.\n",
        "\n",
        "Cada una de ellas se encarga de cargar uno de los subconjuntos utilizados en el desarrollo del modelo (entrenamiento, validación y evaluación)."
      ],
      "metadata": {
        "id": "JZnrL_ctAITR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Ruta al directorio base que contiene todas las imágenes de rayos X a utilizar\n",
        "basepath = \"/content/drive/MyDrive/MBC/Big_Data_Engineering/Big_Data_Final_Project/chest_xray\"\n",
        "\n",
        "# Función para cargar los datos de entrenamiento\n",
        "def train_data_creator(config, batch_size):\n",
        "    # Creamos una instancia de ImageDataGenerator que reescala los colores \n",
        "    # (en formato RGB) de los píxeles de 0 a 1 en lugar de la codificación \n",
        "    # original de 0 a 255, y voltea algunas imágenes horizontalmente al azar\n",
        "    # para aumentar la diversidad de los datos y que el modelo no pierda\n",
        "    # precisión por la orientación de la persona a la hora de tomar la radiografía.\n",
        "    # Esto último solo es necesario en los datos de entrenamiento, por lo que\n",
        "    # no lo repetimos en los datos de validación y evaluación\n",
        "    datagen_train = ImageDataGenerator(rescale=1./255, horizontal_flip=True)\n",
        "\n",
        "    # Usamos la instancia de ImageDataGenerator para cargar los datos del directorio\n",
        "    # especificado con el tamaño, modo de color y tamaño de 'batch' requerido\n",
        "    training_set = datagen_train.flow_from_directory(os.path.join(basepath, \"train\"),\n",
        "                                              target_size=(150, 150),\n",
        "                                              color_mode=\"grayscale\",\n",
        "                                              batch_size=batch_size)\n",
        "\n",
        "    return training_set\n",
        "\n",
        "# Función para cargar los datos de validación\n",
        "def val_data_creator(config, batch_size):\n",
        "    # Creamos una instancia de ImageDataGenerator que reescala los colores \n",
        "    # (en formato RGB) de los píxeles de 0 a 1 en lugar de la codificación \n",
        "    # original de 0 a 255.\n",
        "    datagen_val = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "    # Usamos la instancia de ImageDataGenerator para cargar los datos del directorio\n",
        "    # especificado con el tamaño, modo de color y tamaño de 'batch' requerido\n",
        "    val_set = datagen_val.flow_from_directory(os.path.join(basepath, \"val\"),\n",
        "                                          target_size=(150, 150),\n",
        "                                          color_mode=\"grayscale\",\n",
        "                                          batch_size=batch_size)\n",
        "    return val_set\n",
        "\n",
        "# Función para cargar los datos de evaluación\n",
        "def test_data_creator(config, batch_size):\n",
        "    # Creamos una instancia de ImageDataGenerator que reescala los colores \n",
        "    # (en formato RGB) de los píxeles de 0 a 1 en lugar de la codificación \n",
        "    # original de 0 a 255.\n",
        "    datagen_test = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "    # Usamos la instancia de ImageDataGenerator para cargar los datos del directorio\n",
        "    # especificado con el tamaño, modo de color y tamaño de 'batch' requerido\n",
        "    test_set = datagen_test.flow_from_directory(os.path.join(basepath, \"test\"),\n",
        "                                          target_size=(150, 150),\n",
        "                                          color_mode=\"grayscale\",\n",
        "                                          batch_size=batch_size)\n",
        "    return test_set"
      ],
      "metadata": {
        "id": "uRhaWXLP-hzM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Definimos el modelo que vamos a utilizar"
      ],
      "metadata": {
        "id": "NQsCaMFcGfNd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Función en la que se define el modelo de red neuronal\n",
        "def model_creator(config):\n",
        "    # Utilizamos el modo Secuencial de keras para la construcción de la red\n",
        "    model = tf.keras.Sequential()\n",
        "\n",
        "    # Creamos 5 capas de 32 neuronas convolucionales, definiendo la función de\n",
        "    # activación como 'relu' y el tamaño de los datos de entrada en la primera de todas\n",
        "    model.add(tf.keras.layers.Conv2D(32, kernel_size=(3, 3), input_shape=(150, 150, 1), activation=\"relu\"))\n",
        "    model.add(tf.keras.layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\"))\n",
        "    model.add(tf.keras.layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\"))\n",
        "    model.add(tf.keras.layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\"))\n",
        "    model.add(tf.keras.layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\"))\n",
        "    # Creamos una capa de MaxPooling para reducir la dimensionalidad de la imagen y\n",
        "    # así reducir el coste computacional y minimizar la posibilidad de 'overfitting'\n",
        "    model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "    # Creamos una capa Flatten para convertir la salida bidimensional de la capa\n",
        "    # anterior en una entrada unidimensional de la siguiente\n",
        "    model.add(tf.keras.layers.Flatten())\n",
        "    # Creamos una capa de 10 neuronas completamente conectadas\n",
        "    model.add(tf.keras.layers.Dense(10, activation=\"relu\"))\n",
        "    # Creamos una capa de 2 neuronas como salida, con función de activación 'softmax'\n",
        "    # para realizar una clasificación binaria\n",
        "    model.add(tf.keras.layers.Dense(2, activation=\"softmax\"))\n",
        "\n",
        "    # Compilamos el modelo con 'adam' como optimizador, 'categorical_crossentropy'\n",
        "    # como función de pérdida y obteniendo métricas de 'accuracy', 'precision', \n",
        "    # 'recall' y 'area under the curve' (AUC)\n",
        "    model.compile(optimizer=\"Adam\", \n",
        "                  loss=\"categorical_crossentropy\", \n",
        "                  metrics=[\"accuracy\",\n",
        "                            keras.metrics.Precision(name='precision'), \n",
        "                            keras.metrics.Recall(name='recall'), \n",
        "                            keras.metrics.AUC(name='prc', curve='PR') # precision-recall curve\n",
        "                           ])\n",
        "    \n",
        "    return model"
      ],
      "metadata": {
        "id": "3E_kw6_aG4HJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creamos una instancia del 'Estimator' proporcionado por Orca (Analytics Zoo) a partir del modelo previamente definido"
      ],
      "metadata": {
        "id": "RPOY56rCGlRA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from zoo.orca.learn.tf2 import Estimator\n",
        "\n",
        "est = Estimator.from_keras(model_creator=model_creator, workers_per_node=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CHp0PZHcGSKQ",
        "outputId": "7799df31-4b72-4df3-e210-223efd8b4491"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(pid=5224)\u001b[0m WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/zoo/orca/learn/tf2/tf_runner.py:317: _CollectiveAllReduceStrategyExperimental.__init__ (from tensorflow.python.distribute.collective_all_reduce_strategy) is deprecated and will be removed in a future version.\n",
            "\u001b[2m\u001b[36m(pid=5224)\u001b[0m Instructions for updating:\n",
            "\u001b[2m\u001b[36m(pid=5224)\u001b[0m use distribute.MultiWorkerMirroredStrategy instead\n",
            "\u001b[2m\u001b[36m(pid=5224)\u001b[0m 2022-02-10 12:30:48.294105: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Entrenamiento del modelo"
      ],
      "metadata": {
        "id": "QHs6yyFYOyk8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Definimos 3 épocas y 32 como tamaño de 'batch' para entrenar el Estimador, llamando a las funciones que cargan los datos"
      ],
      "metadata": {
        "id": "lUEBjvqEKo8H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "max_epoch = 3\n",
        "batch_size = 32\n",
        "\n",
        "stats = est.fit(train_data_creator,\n",
        "                epochs=max_epoch,\n",
        "                batch_size=batch_size,\n",
        "                validation_data=val_data_creator)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6CnEPmUnGXua",
        "outputId": "6ad5e106-7ce8-4291-f016-5cbb8f482240"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(pid=5224)\u001b[0m Found 5043 images belonging to 2 classes.\n",
            "\u001b[2m\u001b[36m(pid=5224)\u001b[0m Found 10 images belonging to 2 classes.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(pid=5224)\u001b[0m 2022-02-10 12:30:52.195401: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:766] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_2\"\n",
            "\u001b[2m\u001b[36m(pid=5224)\u001b[0m op: \"FlatMapDataset\"\n",
            "\u001b[2m\u001b[36m(pid=5224)\u001b[0m input: \"TensorDataset/_1\"\n",
            "\u001b[2m\u001b[36m(pid=5224)\u001b[0m attr {\n",
            "\u001b[2m\u001b[36m(pid=5224)\u001b[0m   key: \"Targuments\"\n",
            "\u001b[2m\u001b[36m(pid=5224)\u001b[0m   value {\n",
            "\u001b[2m\u001b[36m(pid=5224)\u001b[0m     list {\n",
            "\u001b[2m\u001b[36m(pid=5224)\u001b[0m     }\n",
            "\u001b[2m\u001b[36m(pid=5224)\u001b[0m   }\n",
            "\u001b[2m\u001b[36m(pid=5224)\u001b[0m }\n",
            "\u001b[2m\u001b[36m(pid=5224)\u001b[0m attr {\n",
            "\u001b[2m\u001b[36m(pid=5224)\u001b[0m   key: \"_cardinality\"\n",
            "\u001b[2m\u001b[36m(pid=5224)\u001b[0m   value {\n",
            "\u001b[2m\u001b[36m(pid=5224)\u001b[0m     i: -2\n",
            "\u001b[2m\u001b[36m(pid=5224)\u001b[0m   }\n",
            "\u001b[2m\u001b[36m(pid=5224)\u001b[0m }\n",
            "\u001b[2m\u001b[36m(pid=5224)\u001b[0m attr {\n",
            "\u001b[2m\u001b[36m(pid=5224)\u001b[0m   key: \"f\"\n",
            "\u001b[2m\u001b[36m(pid=5224)\u001b[0m   value {\n",
            "\u001b[2m\u001b[36m(pid=5224)\u001b[0m     func {\n",
            "\u001b[2m\u001b[36m(pid=5224)\u001b[0m       name: \"__inference_Dataset_flat_map_flat_map_fn_372\"\n",
            "\u001b[2m\u001b[36m(pid=5224)\u001b[0m     }\n",
            "\u001b[2m\u001b[36m(pid=5224)\u001b[0m   }\n",
            "\u001b[2m\u001b[36m(pid=5224)\u001b[0m }\n",
            "\u001b[2m\u001b[36m(pid=5224)\u001b[0m attr {\n",
            "\u001b[2m\u001b[36m(pid=5224)\u001b[0m   key: \"metadata\"\n",
            "\u001b[2m\u001b[36m(pid=5224)\u001b[0m   value {\n",
            "\u001b[2m\u001b[36m(pid=5224)\u001b[0m     s: \"\\n\\020FlatMapDataset:1\"\n",
            "\u001b[2m\u001b[36m(pid=5224)\u001b[0m   }\n",
            "\u001b[2m\u001b[36m(pid=5224)\u001b[0m }\n",
            "\u001b[2m\u001b[36m(pid=5224)\u001b[0m attr {\n",
            "\u001b[2m\u001b[36m(pid=5224)\u001b[0m   key: \"output_shapes\"\n",
            "\u001b[2m\u001b[36m(pid=5224)\u001b[0m   value {\n",
            "\u001b[2m\u001b[36m(pid=5224)\u001b[0m     list {\n",
            "\u001b[2m\u001b[36m(pid=5224)\u001b[0m       shape {\n",
            "\u001b[2m\u001b[36m(pid=5224)\u001b[0m         dim {\n",
            "\u001b[2m\u001b[36m(pid=5224)\u001b[0m           size: -1\n",
            "\u001b[2m\u001b[36m(pid=5224)\u001b[0m         }\n",
            "\u001b[2m\u001b[36m(pid=5224)\u001b[0m         dim {\n",
            "\u001b[2m\u001b[36m(pid=5224)\u001b[0m           size: -1\n",
            "\u001b[2m\u001b[36m(pid=5224)\u001b[0m         }\n",
            "\u001b[2m\u001b[36m(pid=5224)\u001b[0m         dim {\n",
            "\u001b[2m\u001b[36m(pid=5224)\u001b[0m           size: -1\n",
            "\u001b[2m\u001b[36m(pid=5224)\u001b[0m         }\n",
            "\u001b[2m\u001b[36m(pid=5224)\u001b[0m         dim {\n",
            "\u001b[2m\u001b[36m(pid=5224)\u001b[0m           size: -1\n",
            "\u001b[2m\u001b[36m(pid=5224)\u001b[0m         }\n",
            "\u001b[2m\u001b[36m(pid=5224)\u001b[0m       }\n",
            "\u001b[2m\u001b[36m(pid=5224)\u001b[0m       shape {\n",
            "\u001b[2m\u001b[36m(pid=5224)\u001b[0m         dim {\n",
            "\u001b[2m\u001b[36m(pid=5224)\u001b[0m           size: -1\n",
            "\u001b[2m\u001b[36m(pid=5224)\u001b[0m         }\n",
            "\u001b[2m\u001b[36m(pid=5224)\u001b[0m         dim {\n",
            "\u001b[2m\u001b[36m(pid=5224)\u001b[0m           size: -1\n",
            "\u001b[2m\u001b[36m(pid=5224)\u001b[0m         }\n",
            "\u001b[2m\u001b[36m(pid=5224)\u001b[0m       }\n",
            "\u001b[2m\u001b[36m(pid=5224)\u001b[0m     }\n",
            "\u001b[2m\u001b[36m(pid=5224)\u001b[0m   }\n",
            "\u001b[2m\u001b[36m(pid=5224)\u001b[0m }\n",
            "\u001b[2m\u001b[36m(pid=5224)\u001b[0m attr {\n",
            "\u001b[2m\u001b[36m(pid=5224)\u001b[0m   key: \"output_types\"\n",
            "\u001b[2m\u001b[36m(pid=5224)\u001b[0m   value {\n",
            "\u001b[2m\u001b[36m(pid=5224)\u001b[0m     list {\n",
            "\u001b[2m\u001b[36m(pid=5224)\u001b[0m       type: DT_FLOAT\n",
            "\u001b[2m\u001b[36m(pid=5224)\u001b[0m       type: DT_FLOAT\n",
            "\u001b[2m\u001b[36m(pid=5224)\u001b[0m     }\n",
            "\u001b[2m\u001b[36m(pid=5224)\u001b[0m   }\n",
            "\u001b[2m\u001b[36m(pid=5224)\u001b[0m }\n",
            "\u001b[2m\u001b[36m(pid=5224)\u001b[0m . Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n",
            "\u001b[2m\u001b[36m(pid=5224)\u001b[0m 2022-02-10 12:30:52.265726: W tensorflow/core/framework/dataset.cc:744] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(pid=5224)\u001b[0m Epoch 1/3\n",
            "  1/158 [..............................] - ETA: 32:59 - loss: 0.6978 - accuracy: 0.3125 - precision: 0.3125 - recall: 0.3125 - prc: 0.4036\n",
            "  2/158 [..............................] - ETA: 17:46 - loss: 0.6938 - accuracy: 0.4375 - precision: 0.4375 - recall: 0.4375 - prc: 0.4848\n",
            "  3/158 [..............................] - ETA: 16:36 - loss: 0.6808 - accuracy: 0.5208 - precision: 0.5208 - recall: 0.5208 - prc: 0.6277\n",
            "  4/158 [..............................] - ETA: 14:12 - loss: 0.6653 - accuracy: 0.5565 - precision: 0.5565 - recall: 0.5565 - prc: 0.6323\n",
            "  5/158 [..............................] - ETA: 14:26 - loss: 0.6580 - accuracy: 0.5986 - precision: 0.5986 - recall: 0.5986 - prc: 0.6620\n",
            "  6/158 [>.............................] - ETA: 15:18 - loss: 0.6558 - accuracy: 0.6145 - precision: 0.6145 - recall: 0.6145 - prc: 0.6647\n",
            "  7/158 [>.............................] - ETA: 15:13 - loss: 0.6336 - accuracy: 0.6493 - precision: 0.6493 - recall: 0.6493 - prc: 0.6853\n",
            "  8/158 [>.............................] - ETA: 15:08 - loss: 0.6211 - accuracy: 0.6708 - precision: 0.6708 - recall: 0.6708 - prc: 0.6987\n",
            "  9/158 [>.............................] - ETA: 15:02 - loss: 0.6210 - accuracy: 0.6727 - precision: 0.6727 - recall: 0.6727 - prc: 0.6952\n",
            " 10/158 [>.............................] - ETA: 14:58 - loss: 0.6060 - accuracy: 0.6938 - precision: 0.6938 - recall: 0.6938 - prc: 0.7106\n",
            " 11/158 [=>............................] - ETA: 14:52 - loss: 0.5895 - accuracy: 0.7109 - precision: 0.7109 - recall: 0.7109 - prc: 0.7265\n",
            " 12/158 [=>............................] - ETA: 14:48 - loss: 0.5881 - accuracy: 0.7143 - precision: 0.7143 - recall: 0.7143 - prc: 0.7242\n",
            " 13/158 [=>............................] - ETA: 14:42 - loss: 0.5798 - accuracy: 0.7221 - precision: 0.7221 - recall: 0.7221 - prc: 0.7363\n",
            " 14/158 [=>............................] - ETA: 14:36 - loss: 0.5964 - accuracy: 0.7172 - precision: 0.7172 - recall: 0.7172 - prc: 0.7229\n",
            " 15/158 [=>............................] - ETA: 14:31 - loss: 0.6016 - accuracy: 0.7152 - precision: 0.7152 - recall: 0.7152 - prc: 0.7179\n",
            " 16/158 [==>...........................] - ETA: 14:25 - loss: 0.6037 - accuracy: 0.7134 - precision: 0.7134 - recall: 0.7134 - prc: 0.7132\n",
            " 17/158 [==>...........................] - ETA: 14:20 - loss: 0.6001 - accuracy: 0.7175 - precision: 0.7175 - recall: 0.7175 - prc: 0.7144\n",
            " 18/158 [==>...........................] - ETA: 14:15 - loss: 0.5957 - accuracy: 0.7247 - precision: 0.7247 - recall: 0.7247 - prc: 0.7175\n",
            " 19/158 [==>...........................] - ETA: 14:11 - loss: 0.5966 - accuracy: 0.7227 - precision: 0.7227 - recall: 0.7227 - prc: 0.7180\n",
            " 20/158 [==>...........................] - ETA: 14:05 - loss: 0.5980 - accuracy: 0.7209 - precision: 0.7209 - recall: 0.7209 - prc: 0.7184\n",
            " 21/158 [==>...........................] - ETA: 13:58 - loss: 0.5993 - accuracy: 0.7178 - precision: 0.7178 - recall: 0.7178 - prc: 0.7187\n",
            " 22/158 [===>..........................] - ETA: 13:52 - loss: 0.5994 - accuracy: 0.7178 - precision: 0.7178 - recall: 0.7178 - prc: 0.7201\n",
            " 23/158 [===>..........................] - ETA: 13:46 - loss: 0.6028 - accuracy: 0.7109 - precision: 0.7109 - recall: 0.7109 - prc: 0.7189\n",
            " 24/158 [===>..........................] - ETA: 13:41 - loss: 0.6020 - accuracy: 0.7126 - precision: 0.7126 - recall: 0.7126 - prc: 0.7213\n",
            " 25/158 [===>..........................] - ETA: 13:35 - loss: 0.5992 - accuracy: 0.7166 - precision: 0.7166 - recall: 0.7166 - prc: 0.7249\n",
            " 26/158 [===>..........................] - ETA: 13:29 - loss: 0.5995 - accuracy: 0.7143 - precision: 0.7143 - recall: 0.7143 - prc: 0.7240\n",
            " 27/158 [====>.........................] - ETA: 13:23 - loss: 0.5971 - accuracy: 0.7156 - precision: 0.7156 - recall: 0.7156 - prc: 0.7243\n",
            " 28/158 [====>.........................] - ETA: 13:17 - loss: 0.5962 - accuracy: 0.7157 - precision: 0.7157 - recall: 0.7157 - prc: 0.7230\n",
            " 29/158 [====>.........................] - ETA: 13:12 - loss: 0.5924 - accuracy: 0.7180 - precision: 0.7180 - recall: 0.7180 - prc: 0.7251\n",
            " 30/158 [====>.........................] - ETA: 13:05 - loss: 0.5862 - accuracy: 0.7223 - precision: 0.7223 - recall: 0.7223 - prc: 0.7307\n",
            " 31/158 [====>.........................] - ETA: 12:59 - loss: 0.5870 - accuracy: 0.7211 - precision: 0.7211 - recall: 0.7211 - prc: 0.7318\n",
            " 32/158 [=====>........................] - ETA: 12:53 - loss: 0.5884 - accuracy: 0.7171 - precision: 0.7171 - recall: 0.7171 - prc: 0.7307\n",
            " 33/158 [=====>........................] - ETA: 12:47 - loss: 0.5841 - accuracy: 0.7220 - precision: 0.7220 - recall: 0.7220 - prc: 0.7350\n",
            " 34/158 [=====>........................] - ETA: 12:40 - loss: 0.5804 - accuracy: 0.7219 - precision: 0.7219 - recall: 0.7219 - prc: 0.7393\n",
            " 35/158 [=====>........................] - ETA: 12:34 - loss: 0.5740 - accuracy: 0.7245 - precision: 0.7245 - recall: 0.7245 - prc: 0.7482\n",
            " 36/158 [=====>........................] - ETA: 12:28 - loss: 0.5695 - accuracy: 0.7234 - precision: 0.7234 - recall: 0.7234 - prc: 0.7553\n",
            " 37/158 [======>.......................] - ETA: 12:22 - loss: 0.5638 - accuracy: 0.7250 - precision: 0.7250 - recall: 0.7250 - prc: 0.7638\n",
            " 38/158 [======>.......................] - ETA: 12:16 - loss: 0.5595 - accuracy: 0.7257 - precision: 0.7257 - recall: 0.7257 - prc: 0.7700\n",
            " 39/158 [======>.......................] - ETA: 12:09 - loss: 0.5559 - accuracy: 0.7263 - precision: 0.7263 - recall: 0.7263 - prc: 0.7750\n",
            "\u001b[2m\u001b[36m(pid=5224)\u001b[0m \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            " 40/158 [======>.......................] - ETA: 12:03 - loss: 0.5489 - accuracy: 0.7293 - precision: 0.7293 - recall: 0.7293 - prc: 0.7834\n",
            " 41/158 [======>.......................] - ETA: 11:57 - loss: 0.5458 - accuracy: 0.7290 - precision: 0.7290 - recall: 0.7290 - prc: 0.7874\n",
            " 42/158 [======>.......................] - ETA: 11:51 - loss: 0.5404 - accuracy: 0.7325 - precision: 0.7325 - recall: 0.7325 - prc: 0.7933\n",
            " 43/158 [=======>......................] - ETA: 11:45 - loss: 0.5338 - accuracy: 0.7344 - precision: 0.7344 - recall: 0.7344 - prc: 0.8007\n",
            " 44/158 [=======>......................] - ETA: 11:39 - loss: 0.5292 - accuracy: 0.7355 - precision: 0.7355 - recall: 0.7355 - prc: 0.8054\n",
            " 45/158 [=======>......................] - ETA: 11:33 - loss: 0.5235 - accuracy: 0.7351 - precision: 0.7351 - recall: 0.7351 - prc: 0.8114\n",
            " 46/158 [=======>......................] - ETA: 11:27 - loss: 0.5163 - accuracy: 0.7375 - precision: 0.7375 - recall: 0.7375 - prc: 0.8181\n",
            " 47/158 [=======>......................] - ETA: 11:21 - loss: 0.5121 - accuracy: 0.7378 - precision: 0.7378 - recall: 0.7378 - prc: 0.8217\n",
            " 48/158 [========>.....................] - ETA: 11:15 - loss: 0.5076 - accuracy: 0.7406 - precision: 0.7406 - recall: 0.7406 - prc: 0.8258\n",
            " 49/158 [========>.....................] - ETA: 11:09 - loss: 0.5026 - accuracy: 0.7415 - precision: 0.7415 - recall: 0.7415 - prc: 0.8298\n",
            " 50/158 [========>.....................] - ETA: 11:09 - loss: 0.5004 - accuracy: 0.7410 - precision: 0.7410 - recall: 0.7410 - prc: 0.8316\n",
            " 51/158 [========>.....................] - ETA: 11:07 - loss: 0.4978 - accuracy: 0.7387 - precision: 0.7387 - recall: 0.7387 - prc: 0.8336\n",
            " 52/158 [========>.....................] - ETA: 11:01 - loss: 0.4948 - accuracy: 0.7377 - precision: 0.7377 - recall: 0.7377 - prc: 0.8362\n",
            " 53/158 [=========>....................] - ETA: 11:00 - loss: 0.4927 - accuracy: 0.7374 - precision: 0.7374 - recall: 0.7374 - prc: 0.8380\n",
            " 54/158 [=========>....................] - ETA: 10:54 - loss: 0.4892 - accuracy: 0.7394 - precision: 0.7394 - recall: 0.7394 - prc: 0.8411\n",
            " 55/158 [=========>....................] - ETA: 10:47 - loss: 0.4872 - accuracy: 0.7378 - precision: 0.7378 - recall: 0.7378 - prc: 0.8428\n",
            " 56/158 [=========>....................] - ETA: 10:41 - loss: 0.4826 - accuracy: 0.7375 - precision: 0.7375 - recall: 0.7375 - prc: 0.8461\n",
            " 57/158 [=========>....................] - ETA: 10:34 - loss: 0.4787 - accuracy: 0.7394 - precision: 0.7394 - recall: 0.7394 - prc: 0.8489\n",
            " 58/158 [==========>...................] - ETA: 10:28 - loss: 0.4772 - accuracy: 0.7385 - precision: 0.7385 - recall: 0.7385 - prc: 0.8500\n",
            " 59/158 [==========>...................] - ETA: 10:21 - loss: 0.4732 - accuracy: 0.7376 - precision: 0.7376 - recall: 0.7376 - prc: 0.8527\n",
            " 60/158 [==========>...................] - ETA: 10:15 - loss: 0.4705 - accuracy: 0.7362 - precision: 0.7362 - recall: 0.7362 - prc: 0.8544\n",
            " 61/158 [==========>...................] - ETA: 10:08 - loss: 0.4657 - accuracy: 0.7380 - precision: 0.7380 - recall: 0.7380 - prc: 0.8577\n",
            " 62/158 [==========>...................] - ETA: 10:01 - loss: 0.4738 - accuracy: 0.7372 - precision: 0.7372 - recall: 0.7372 - prc: 0.8535\n",
            " 63/158 [==========>...................] - ETA: 9:55 - loss: 0.4684 - accuracy: 0.7399 - precision: 0.7399 - recall: 0.7399 - prc: 0.8572 \n",
            " 64/158 [===========>..................] - ETA: 9:48 - loss: 0.4664 - accuracy: 0.7410 - precision: 0.7410 - recall: 0.7410 - prc: 0.8589\n",
            " 65/158 [===========>..................] - ETA: 9:41 - loss: 0.4662 - accuracy: 0.7426 - precision: 0.7426 - recall: 0.7426 - prc: 0.8598\n",
            " 66/158 [===========>..................] - ETA: 9:35 - loss: 0.4642 - accuracy: 0.7437 - precision: 0.7437 - recall: 0.7437 - prc: 0.8611\n",
            " 67/158 [===========>..................] - ETA: 9:28 - loss: 0.4600 - accuracy: 0.7443 - precision: 0.7443 - recall: 0.7443 - prc: 0.8638\n",
            " 68/158 [===========>..................] - ETA: 9:22 - loss: 0.4580 - accuracy: 0.7466 - precision: 0.7466 - recall: 0.7466 - prc: 0.8650\n",
            " 69/158 [============>.................] - ETA: 9:16 - loss: 0.4562 - accuracy: 0.7490 - precision: 0.7490 - recall: 0.7490 - prc: 0.8661\n",
            " 70/158 [============>.................] - ETA: 9:09 - loss: 0.4568 - accuracy: 0.7503 - precision: 0.7503 - recall: 0.7503 - prc: 0.8654\n",
            " 71/158 [============>.................] - ETA: 9:03 - loss: 0.4567 - accuracy: 0.7512 - precision: 0.7512 - recall: 0.7512 - prc: 0.8652\n",
            " 72/158 [============>.................] - ETA: 8:56 - loss: 0.4576 - accuracy: 0.7521 - precision: 0.7521 - recall: 0.7521 - prc: 0.8646\n",
            " 73/158 [============>.................] - ETA: 8:50 - loss: 0.4566 - accuracy: 0.7538 - precision: 0.7538 - recall: 0.7538 - prc: 0.8653\n",
            " 74/158 [=============>................] - ETA: 8:44 - loss: 0.4553 - accuracy: 0.7558 - precision: 0.7558 - recall: 0.7558 - prc: 0.8664\n",
            " 75/158 [=============>................] - ETA: 8:37 - loss: 0.4564 - accuracy: 0.7562 - precision: 0.7562 - recall: 0.7562 - prc: 0.8657\n",
            " 76/158 [=============>................] - ETA: 8:31 - loss: 0.4584 - accuracy: 0.7561 - precision: 0.7561 - recall: 0.7561 - prc: 0.8645\n",
            " 77/158 [=============>................] - ETA: 8:25 - loss: 0.4563 - accuracy: 0.7572 - precision: 0.7572 - recall: 0.7572 - prc: 0.8658\n",
            " 78/158 [=============>................] - ETA: 8:18 - loss: 0.4552 - accuracy: 0.7588 - precision: 0.7588 - recall: 0.7588 - prc: 0.8665\n",
            " 79/158 [==============>...............] - ETA: 8:12 - loss: 0.4533 - accuracy: 0.7614 - precision: 0.7614 - recall: 0.7614 - prc: 0.8679\n",
            " 80/158 [==============>...............] - ETA: 8:06 - loss: 0.4534 - accuracy: 0.7633 - precision: 0.7633 - recall: 0.7633 - prc: 0.8680\n",
            " 81/158 [==============>...............] - ETA: 7:59 - loss: 0.4524 - accuracy: 0.7654 - precision: 0.7654 - recall: 0.7654 - prc: 0.8688\n",
            " 82/158 [==============>...............] - ETA: 7:53 - loss: 0.4522 - accuracy: 0.7660 - precision: 0.7660 - recall: 0.7660 - prc: 0.8690\n",
            " 83/158 [==============>...............] - ETA: 7:47 - loss: 0.4511 - accuracy: 0.7666 - precision: 0.7666 - recall: 0.7666 - prc: 0.8697\n",
            " 84/158 [==============>...............] - ETA: 7:40 - loss: 0.4496 - accuracy: 0.7671 - precision: 0.7671 - recall: 0.7671 - prc: 0.8706\n",
            " 85/158 [===============>..............] - ETA: 7:34 - loss: 0.4506 - accuracy: 0.7673 - precision: 0.7673 - recall: 0.7673 - prc: 0.8701\n",
            " 86/158 [===============>..............] - ETA: 7:28 - loss: 0.4486 - accuracy: 0.7685 - precision: 0.7685 - recall: 0.7685 - prc: 0.8714\n",
            " 87/158 [===============>..............] - ETA: 7:21 - loss: 0.4482 - accuracy: 0.7694 - precision: 0.7694 - recall: 0.7694 - prc: 0.8717\n",
            " 88/158 [===============>..............] - ETA: 7:15 - loss: 0.4464 - accuracy: 0.7710 - precision: 0.7710 - recall: 0.7710 - prc: 0.8728\n",
            " 89/158 [===============>..............] - ETA: 7:09 - loss: 0.4452 - accuracy: 0.7725 - precision: 0.7725 - recall: 0.7725 - prc: 0.8736\n",
            " 90/158 [================>.............] - ETA: 7:02 - loss: 0.4442 - accuracy: 0.7733 - precision: 0.7733 - recall: 0.7733 - prc: 0.8742\n",
            " 91/158 [================>.............] - ETA: 6:56 - loss: 0.4431 - accuracy: 0.7747 - precision: 0.7747 - recall: 0.7747 - prc: 0.8750\n",
            " 92/158 [================>.............] - ETA: 6:50 - loss: 0.4419 - accuracy: 0.7758 - precision: 0.7758 - recall: 0.7758 - prc: 0.8757\n",
            " 93/158 [================>.............] - ETA: 6:44 - loss: 0.4403 - accuracy: 0.7769 - precision: 0.7769 - recall: 0.7769 - prc: 0.8768\n",
            " 94/158 [================>.............] - ETA: 6:37 - loss: 0.4411 - accuracy: 0.7760 - precision: 0.7760 - recall: 0.7760 - prc: 0.8761\n",
            " 95/158 [=================>............] - ETA: 6:31 - loss: 0.4399 - accuracy: 0.7770 - precision: 0.7770 - recall: 0.7770 - prc: 0.8770\n",
            " 96/158 [=================>............] - ETA: 6:25 - loss: 0.4393 - accuracy: 0.7771 - precision: 0.7771 - recall: 0.7771 - prc: 0.8773\n",
            " 97/158 [=================>............] - ETA: 6:18 - loss: 0.4368 - accuracy: 0.7787 - precision: 0.7787 - recall: 0.7787 - prc: 0.8789\n",
            " 98/158 [=================>............] - ETA: 6:12 - loss: 0.4378 - accuracy: 0.7797 - precision: 0.7797 - recall: 0.7797 - prc: 0.8785\n",
            " 99/158 [=================>............] - ETA: 6:06 - loss: 0.4360 - accuracy: 0.7816 - precision: 0.7816 - recall: 0.7816 - prc: 0.8798\n",
            "100/158 [=================>............] - ETA: 6:00 - loss: 0.4347 - accuracy: 0.7826 - precision: 0.7826 - recall: 0.7826 - prc: 0.8806\n",
            "101/158 [==================>...........] - ETA: 5:53 - loss: 0.4325 - accuracy: 0.7838 - precision: 0.7838 - recall: 0.7838 - prc: 0.8820\n",
            "102/158 [==================>...........] - ETA: 5:47 - loss: 0.4327 - accuracy: 0.7831 - precision: 0.7831 - recall: 0.7831 - prc: 0.8817\n",
            "103/158 [==================>...........] - ETA: 5:41 - loss: 0.4321 - accuracy: 0.7834 - precision: 0.7834 - recall: 0.7834 - prc: 0.8821\n",
            "104/158 [==================>...........] - ETA: 5:35 - loss: 0.4312 - accuracy: 0.7843 - precision: 0.7843 - recall: 0.7843 - prc: 0.8827\n",
            "105/158 [==================>...........] - ETA: 5:28 - loss: 0.4311 - accuracy: 0.7849 - precision: 0.7849 - recall: 0.7849 - prc: 0.8829\n",
            "106/158 [===================>..........] - ETA: 5:22 - loss: 0.4306 - accuracy: 0.7857 - precision: 0.7857 - recall: 0.7857 - prc: 0.8833\n",
            "107/158 [===================>..........] - ETA: 5:16 - loss: 0.4302 - accuracy: 0.7866 - precision: 0.7866 - recall: 0.7866 - prc: 0.8837\n",
            "108/158 [===================>..........] - ETA: 5:09 - loss: 0.4288 - accuracy: 0.7877 - precision: 0.7877 - recall: 0.7877 - prc: 0.8845\n",
            "109/158 [===================>..........] - ETA: 5:03 - loss: 0.4280 - accuracy: 0.7873 - precision: 0.7873 - recall: 0.7873 - prc: 0.8849\n",
            "110/158 [===================>..........] - ETA: 4:57 - loss: 0.4263 - accuracy: 0.7887 - precision: 0.7887 - recall: 0.7887 - prc: 0.8860\n",
            "111/158 [====================>.........] - ETA: 4:51 - loss: 0.4243 - accuracy: 0.7906 - precision: 0.7906 - recall: 0.7906 - prc: 0.8873\n",
            "112/158 [====================>.........] - ETA: 4:45 - loss: 0.4238 - accuracy: 0.7917 - precision: 0.7917 - recall: 0.7917 - prc: 0.8878\n",
            "113/158 [====================>.........] - ETA: 4:38 - loss: 0.4228 - accuracy: 0.7930 - precision: 0.7930 - recall: 0.7930 - prc: 0.8885\n",
            "114/158 [====================>.........] - ETA: 4:32 - loss: 0.4205 - accuracy: 0.7942 - precision: 0.7942 - recall: 0.7942 - prc: 0.8899\n",
            "115/158 [====================>.........] - ETA: 4:26 - loss: 0.4193 - accuracy: 0.7947 - precision: 0.7947 - recall: 0.7947 - prc: 0.8905\n",
            "116/158 [=====================>........] - ETA: 4:20 - loss: 0.4203 - accuracy: 0.7954 - precision: 0.7954 - recall: 0.7954 - prc: 0.8902\n",
            "117/158 [=====================>........] - ETA: 4:13 - loss: 0.4189 - accuracy: 0.7966 - precision: 0.7966 - recall: 0.7966 - prc: 0.8911\n",
            "118/158 [=====================>........] - ETA: 4:07 - loss: 0.4176 - accuracy: 0.7980 - precision: 0.7980 - recall: 0.7980 - prc: 0.8920\n",
            "119/158 [=====================>........] - ETA: 4:01 - loss: 0.4166 - accuracy: 0.7982 - precision: 0.7982 - recall: 0.7982 - prc: 0.8924\n",
            "120/158 [=====================>........] - ETA: 3:55 - loss: 0.4154 - accuracy: 0.7991 - precision: 0.7991 - recall: 0.7991 - prc: 0.8932\n",
            "121/158 [=====================>........] - ETA: 3:49 - loss: 0.4141 - accuracy: 0.8002 - precision: 0.8002 - recall: 0.8002 - prc: 0.8940\n",
            "122/158 [======================>.......] - ETA: 3:42 - loss: 0.4118 - accuracy: 0.8019 - precision: 0.8019 - recall: 0.8019 - prc: 0.8954\n",
            "123/158 [======================>.......] - ETA: 3:36 - loss: 0.4113 - accuracy: 0.8022 - precision: 0.8022 - recall: 0.8022 - prc: 0.8956\n",
            "124/158 [======================>.......] - ETA: 3:30 - loss: 0.4107 - accuracy: 0.8030 - precision: 0.8030 - recall: 0.8030 - prc: 0.8961\n",
            "125/158 [======================>.......] - ETA: 3:24 - loss: 0.4098 - accuracy: 0.8036 - precision: 0.8036 - recall: 0.8036 - prc: 0.8966\n",
            "126/158 [======================>.......] - ETA: 3:18 - loss: 0.4096 - accuracy: 0.8042 - precision: 0.8042 - recall: 0.8042 - prc: 0.8968\n",
            "127/158 [=======================>......] - ETA: 3:11 - loss: 0.4086 - accuracy: 0.8050 - precision: 0.8050 - recall: 0.8050 - prc: 0.8974\n",
            "128/158 [=======================>......] - ETA: 3:05 - loss: 0.4076 - accuracy: 0.8063 - precision: 0.8063 - recall: 0.8063 - prc: 0.8981\n",
            "129/158 [=======================>......] - ETA: 2:59 - loss: 0.4072 - accuracy: 0.8075 - precision: 0.8075 - recall: 0.8075 - prc: 0.8986\n",
            "130/158 [=======================>......] - ETA: 2:53 - loss: 0.4060 - accuracy: 0.8081 - precision: 0.8081 - recall: 0.8081 - prc: 0.8992\n",
            "131/158 [=======================>......] - ETA: 2:47 - loss: 0.4047 - accuracy: 0.8086 - precision: 0.8086 - recall: 0.8086 - prc: 0.8999\n",
            "132/158 [========================>.....] - ETA: 2:40 - loss: 0.4065 - accuracy: 0.8076 - precision: 0.8076 - recall: 0.8076 - prc: 0.8988\n",
            "133/158 [========================>.....] - ETA: 2:34 - loss: 0.4055 - accuracy: 0.8084 - precision: 0.8084 - recall: 0.8084 - prc: 0.8993\n",
            "134/158 [========================>.....] - ETA: 2:28 - loss: 0.4048 - accuracy: 0.8087 - precision: 0.8087 - recall: 0.8087 - prc: 0.8997\n",
            "135/158 [========================>.....] - ETA: 2:22 - loss: 0.4041 - accuracy: 0.8094 - precision: 0.8094 - recall: 0.8094 - prc: 0.9001\n",
            "136/158 [========================>.....] - ETA: 2:15 - loss: 0.4033 - accuracy: 0.8096 - precision: 0.8096 - recall: 0.8096 - prc: 0.9005\n",
            "137/158 [=========================>....] - ETA: 2:09 - loss: 0.4015 - accuracy: 0.8106 - precision: 0.8106 - recall: 0.8106 - prc: 0.9015\n",
            "138/158 [=========================>....] - ETA: 2:03 - loss: 0.4004 - accuracy: 0.8117 - precision: 0.8117 - recall: 0.8117 - prc: 0.9022\n",
            "139/158 [=========================>....] - ETA: 1:57 - loss: 0.4013 - accuracy: 0.8117 - precision: 0.8117 - recall: 0.8117 - prc: 0.9018\n",
            "140/158 [=========================>....] - ETA: 1:51 - loss: 0.3998 - accuracy: 0.8126 - precision: 0.8126 - recall: 0.8126 - prc: 0.9026\n",
            "141/158 [=========================>....] - ETA: 1:44 - loss: 0.3986 - accuracy: 0.8131 - precision: 0.8131 - recall: 0.8131 - prc: 0.9032\n",
            "142/158 [=========================>....] - ETA: 1:38 - loss: 0.3971 - accuracy: 0.8142 - precision: 0.8142 - recall: 0.8142 - prc: 0.9040\n",
            "143/158 [==========================>...] - ETA: 1:32 - loss: 0.3968 - accuracy: 0.8148 - precision: 0.8148 - recall: 0.8148 - prc: 0.9043\n",
            "144/158 [==========================>...] - ETA: 1:26 - loss: 0.3966 - accuracy: 0.8152 - precision: 0.8152 - recall: 0.8152 - prc: 0.9045\n",
            "145/158 [==========================>...] - ETA: 1:20 - loss: 0.3951 - accuracy: 0.8163 - precision: 0.8163 - recall: 0.8163 - prc: 0.9053\n",
            "146/158 [==========================>...] - ETA: 1:14 - loss: 0.3945 - accuracy: 0.8167 - precision: 0.8167 - recall: 0.8167 - prc: 0.9056\n",
            "147/158 [==========================>...] - ETA: 1:07 - loss: 0.3927 - accuracy: 0.8177 - precision: 0.8177 - recall: 0.8177 - prc: 0.9066\n",
            "148/158 [===========================>..] - ETA: 1:01 - loss: 0.3909 - accuracy: 0.8185 - precision: 0.8185 - recall: 0.8185 - prc: 0.9075\n",
            "149/158 [===========================>..] - ETA: 55s - loss: 0.3894 - accuracy: 0.8193 - precision: 0.8193 - recall: 0.8193 - prc: 0.9083 \n",
            "150/158 [===========================>..] - ETA: 49s - loss: 0.3883 - accuracy: 0.8197 - precision: 0.8197 - recall: 0.8197 - prc: 0.9087\n",
            "151/158 [===========================>..] - ETA: 43s - loss: 0.3877 - accuracy: 0.8203 - precision: 0.8203 - recall: 0.8203 - prc: 0.9091\n",
            "152/158 [===========================>..] - ETA: 36s - loss: 0.3869 - accuracy: 0.8213 - precision: 0.8213 - recall: 0.8213 - prc: 0.9096\n",
            "153/158 [============================>.] - ETA: 30s - loss: 0.3869 - accuracy: 0.8216 - precision: 0.8216 - recall: 0.8216 - prc: 0.9097\n",
            "154/158 [============================>.] - ETA: 24s - loss: 0.3860 - accuracy: 0.8224 - precision: 0.8224 - recall: 0.8224 - prc: 0.9102\n",
            "155/158 [============================>.] - ETA: 18s - loss: 0.3852 - accuracy: 0.8233 - precision: 0.8233 - recall: 0.8233 - prc: 0.9107\n",
            "156/158 [============================>.] - ETA: 12s - loss: 0.3846 - accuracy: 0.8239 - precision: 0.8239 - recall: 0.8239 - prc: 0.9111\n",
            "157/158 [============================>.] - ETA: 6s - loss: 0.3844 - accuracy: 0.8238 - precision: 0.8238 - recall: 0.8238 - prc: 0.9111 \n",
            "158/158 [==============================] - ETA: 0s - loss: 0.3835 - accuracy: 0.8245 - precision: 0.8245 - recall: 0.8245 - prc: 0.9116\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(pid=5224)\u001b[0m 2022-02-10 12:47:11.720466: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:766] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_2\"\n",
            "\u001b[2m\u001b[36m(pid=5224)\u001b[0m op: \"FlatMapDataset\"\n",
            "\u001b[2m\u001b[36m(pid=5224)\u001b[0m input: \"TensorDataset/_1\"\n",
            "\u001b[2m\u001b[36m(pid=5224)\u001b[0m attr {\n",
            "\u001b[2m\u001b[36m(pid=5224)\u001b[0m   key: \"Targuments\"\n",
            "\u001b[2m\u001b[36m(pid=5224)\u001b[0m   value {\n",
            "\u001b[2m\u001b[36m(pid=5224)\u001b[0m     list {\n",
            "\u001b[2m\u001b[36m(pid=5224)\u001b[0m     }\n",
            "\u001b[2m\u001b[36m(pid=5224)\u001b[0m   }\n",
            "\u001b[2m\u001b[36m(pid=5224)\u001b[0m }\n",
            "\u001b[2m\u001b[36m(pid=5224)\u001b[0m attr {\n",
            "\u001b[2m\u001b[36m(pid=5224)\u001b[0m   key: \"_cardinality\"\n",
            "\u001b[2m\u001b[36m(pid=5224)\u001b[0m   value {\n",
            "\u001b[2m\u001b[36m(pid=5224)\u001b[0m     i: -2\n",
            "\u001b[2m\u001b[36m(pid=5224)\u001b[0m   }\n",
            "\u001b[2m\u001b[36m(pid=5224)\u001b[0m }\n",
            "\u001b[2m\u001b[36m(pid=5224)\u001b[0m attr {\n",
            "\u001b[2m\u001b[36m(pid=5224)\u001b[0m   key: \"f\"\n",
            "\u001b[2m\u001b[36m(pid=5224)\u001b[0m   value {\n",
            "\u001b[2m\u001b[36m(pid=5224)\u001b[0m     func {\n",
            "\u001b[2m\u001b[36m(pid=5224)\u001b[0m       name: \"__inference_Dataset_flat_map_flat_map_fn_3521\"\n",
            "\u001b[2m\u001b[36m(pid=5224)\u001b[0m     }\n",
            "\u001b[2m\u001b[36m(pid=5224)\u001b[0m   }\n",
            "\u001b[2m\u001b[36m(pid=5224)\u001b[0m }\n",
            "\u001b[2m\u001b[36m(pid=5224)\u001b[0m attr {\n",
            "\u001b[2m\u001b[36m(pid=5224)\u001b[0m   key: \"metadata\"\n",
            "\u001b[2m\u001b[36m(pid=5224)\u001b[0m   value {\n",
            "\u001b[2m\u001b[36m(pid=5224)\u001b[0m     s: \"\\n\\021FlatMapDataset:21\"\n",
            "\u001b[2m\u001b[36m(pid=5224)\u001b[0m   }\n",
            "\u001b[2m\u001b[36m(pid=5224)\u001b[0m }\n",
            "\u001b[2m\u001b[36m(pid=5224)\u001b[0m attr {\n",
            "\u001b[2m\u001b[36m(pid=5224)\u001b[0m   key: \"output_shapes\"\n",
            "\u001b[2m\u001b[36m(pid=5224)\u001b[0m   value {\n",
            "\u001b[2m\u001b[36m(pid=5224)\u001b[0m     list {\n",
            "\u001b[2m\u001b[36m(pid=5224)\u001b[0m       shape {\n",
            "\u001b[2m\u001b[36m(pid=5224)\u001b[0m         dim {\n",
            "\u001b[2m\u001b[36m(pid=5224)\u001b[0m           size: -1\n",
            "\u001b[2m\u001b[36m(pid=5224)\u001b[0m         }\n",
            "\u001b[2m\u001b[36m(pid=5224)\u001b[0m         dim {\n",
            "\u001b[2m\u001b[36m(pid=5224)\u001b[0m           size: -1\n",
            "\u001b[2m\u001b[36m(pid=5224)\u001b[0m         }\n",
            "\u001b[2m\u001b[36m(pid=5224)\u001b[0m         dim {\n",
            "\u001b[2m\u001b[36m(pid=5224)\u001b[0m           size: -1\n",
            "\u001b[2m\u001b[36m(pid=5224)\u001b[0m         }\n",
            "\u001b[2m\u001b[36m(pid=5224)\u001b[0m         dim {\n",
            "\u001b[2m\u001b[36m(pid=5224)\u001b[0m           size: -1\n",
            "\u001b[2m\u001b[36m(pid=5224)\u001b[0m         }\n",
            "\u001b[2m\u001b[36m(pid=5224)\u001b[0m       }\n",
            "\u001b[2m\u001b[36m(pid=5224)\u001b[0m       shape {\n",
            "\u001b[2m\u001b[36m(pid=5224)\u001b[0m         dim {\n",
            "\u001b[2m\u001b[36m(pid=5224)\u001b[0m           size: -1\n",
            "\u001b[2m\u001b[36m(pid=5224)\u001b[0m         }\n",
            "\u001b[2m\u001b[36m(pid=5224)\u001b[0m         dim {\n",
            "\u001b[2m\u001b[36m(pid=5224)\u001b[0m           size: -1\n",
            "\u001b[2m\u001b[36m(pid=5224)\u001b[0m         }\n",
            "\u001b[2m\u001b[36m(pid=5224)\u001b[0m       }\n",
            "\u001b[2m\u001b[36m(pid=5224)\u001b[0m     }\n",
            "\u001b[2m\u001b[36m(pid=5224)\u001b[0m   }\n",
            "\u001b[2m\u001b[36m(pid=5224)\u001b[0m }\n",
            "\u001b[2m\u001b[36m(pid=5224)\u001b[0m attr {\n",
            "\u001b[2m\u001b[36m(pid=5224)\u001b[0m   key: \"output_types\"\n",
            "\u001b[2m\u001b[36m(pid=5224)\u001b[0m   value {\n",
            "\u001b[2m\u001b[36m(pid=5224)\u001b[0m     list {\n",
            "\u001b[2m\u001b[36m(pid=5224)\u001b[0m       type: DT_FLOAT\n",
            "\u001b[2m\u001b[36m(pid=5224)\u001b[0m       type: DT_FLOAT\n",
            "\u001b[2m\u001b[36m(pid=5224)\u001b[0m     }\n",
            "\u001b[2m\u001b[36m(pid=5224)\u001b[0m   }\n",
            "\u001b[2m\u001b[36m(pid=5224)\u001b[0m }\n",
            "\u001b[2m\u001b[36m(pid=5224)\u001b[0m . Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n",
            "\u001b[2m\u001b[36m(pid=5224)\u001b[0m 2022-02-10 12:47:11.771730: W tensorflow/core/framework/dataset.cc:744] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n",
            "\u001b[2m\u001b[36m(pid=5224)\u001b[0m 2022-02-10 12:47:13.949357: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at multi_device_iterator_ops.cc:789 : NOT_FOUND: Resource AnonymousMultiDeviceIterator/AnonymousMultiDeviceIterator3/N10tensorflow4data12_GLOBAL__N_119MultiDeviceIteratorE does not exist.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(pid=5224)\u001b[0m \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r158/158 [==============================] - 982s 6s/step - loss: 0.3835 - accuracy: 0.8245 - precision: 0.8245 - recall: 0.8245 - prc: 0.9116 - val_loss: 0.2573 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_prc: 1.0000\n",
            "\u001b[2m\u001b[36m(pid=5224)\u001b[0m Epoch 2/3\n",
            "  1/158 [..............................] - ETA: 18:27 - loss: 0.2018 - accuracy: 0.9375 - precision: 0.9375 - recall: 0.9375 - prc: 0.9805\n",
            "  2/158 [..............................] - ETA: 15:54 - loss: 0.2297 - accuracy: 0.9219 - precision: 0.9219 - recall: 0.9219 - prc: 0.9770\n",
            "  3/158 [..............................] - ETA: 15:38 - loss: 0.2831 - accuracy: 0.9062 - precision: 0.9062 - recall: 0.9062 - prc: 0.9651\n",
            "  4/158 [..............................] - ETA: 15:32 - loss: 0.2966 - accuracy: 0.8906 - precision: 0.8906 - recall: 0.8906 - prc: 0.9605\n",
            "  5/158 [..............................] - ETA: 15:25 - loss: 0.2869 - accuracy: 0.9062 - precision: 0.9062 - recall: 0.9062 - prc: 0.9671\n",
            "  6/158 [>.............................] - ETA: 15:18 - loss: 0.2908 - accuracy: 0.9010 - precision: 0.9010 - recall: 0.9010 - prc: 0.9637\n",
            "  7/158 [>.............................] - ETA: 15:13 - loss: 0.2900 - accuracy: 0.9018 - precision: 0.9018 - recall: 0.9018 - prc: 0.9612\n",
            "  8/158 [>.............................] - ETA: 15:09 - loss: 0.2917 - accuracy: 0.9023 - precision: 0.9023 - recall: 0.9023 - prc: 0.9603\n",
            "  9/158 [>.............................] - ETA: 15:03 - loss: 0.2855 - accuracy: 0.9062 - precision: 0.9062 - recall: 0.9062 - prc: 0.9620\n",
            " 10/158 [>.............................] - ETA: 14:57 - loss: 0.2929 - accuracy: 0.9094 - precision: 0.9094 - recall: 0.9094 - prc: 0.9620\n",
            " 11/158 [=>............................] - ETA: 14:50 - loss: 0.2920 - accuracy: 0.9091 - precision: 0.9091 - recall: 0.9091 - prc: 0.9619\n",
            " 12/158 [=>............................] - ETA: 14:42 - loss: 0.2880 - accuracy: 0.9141 - precision: 0.9141 - recall: 0.9141 - prc: 0.9645\n",
            " 13/158 [=>............................] - ETA: 14:36 - loss: 0.2939 - accuracy: 0.9087 - precision: 0.9087 - recall: 0.9087 - prc: 0.9615\n",
            " 14/158 [=>............................] - ETA: 14:30 - loss: 0.2923 - accuracy: 0.9107 - precision: 0.9107 - recall: 0.9107 - prc: 0.9628\n",
            " 15/158 [=>............................] - ETA: 14:25 - loss: 0.2803 - accuracy: 0.9125 - precision: 0.9125 - recall: 0.9125 - prc: 0.9646\n",
            " 16/158 [==>...........................] - ETA: 14:19 - loss: 0.3106 - accuracy: 0.9062 - precision: 0.9062 - recall: 0.9062 - prc: 0.9529\n",
            " 17/158 [==>...........................] - ETA: 14:13 - loss: 0.3093 - accuracy: 0.9062 - precision: 0.9062 - recall: 0.9062 - prc: 0.9534\n",
            " 18/158 [==>...........................] - ETA: 14:06 - loss: 0.3055 - accuracy: 0.9115 - precision: 0.9115 - recall: 0.9115 - prc: 0.9561\n",
            " 19/158 [==>...........................] - ETA: 14:00 - loss: 0.3034 - accuracy: 0.9128 - precision: 0.9128 - recall: 0.9128 - prc: 0.9570\n",
            " 20/158 [==>...........................] - ETA: 13:54 - loss: 0.3024 - accuracy: 0.9125 - precision: 0.9125 - recall: 0.9125 - prc: 0.9573\n",
            " 21/158 [==>...........................] - ETA: 13:47 - loss: 0.3016 - accuracy: 0.9122 - precision: 0.9122 - recall: 0.9122 - prc: 0.9570\n",
            " 22/158 [===>..........................] - ETA: 13:41 - loss: 0.3033 - accuracy: 0.9119 - precision: 0.9119 - recall: 0.9119 - prc: 0.9574\n",
            " 23/158 [===>..........................] - ETA: 13:35 - loss: 0.3017 - accuracy: 0.9158 - precision: 0.9158 - recall: 0.9158 - prc: 0.9597\n",
            " 24/158 [===>..........................] - ETA: 13:29 - loss: 0.2997 - accuracy: 0.9154 - precision: 0.9154 - recall: 0.9154 - prc: 0.9597\n",
            " 25/158 [===>..........................] - ETA: 13:23 - loss: 0.2962 - accuracy: 0.9175 - precision: 0.9175 - recall: 0.9175 - prc: 0.9612\n",
            " 26/158 [===>..........................] - ETA: 13:16 - loss: 0.3017 - accuracy: 0.9171 - precision: 0.9171 - recall: 0.9171 - prc: 0.9597\n",
            " 27/158 [====>.........................] - ETA: 13:10 - loss: 0.2958 - accuracy: 0.9190 - precision: 0.9190 - recall: 0.9190 - prc: 0.9613\n",
            " 28/158 [====>.........................] - ETA: 13:04 - loss: 0.2987 - accuracy: 0.9174 - precision: 0.9174 - recall: 0.9174 - prc: 0.9604\n",
            " 29/158 [====>.........................] - ETA: 12:58 - loss: 0.2989 - accuracy: 0.9181 - precision: 0.9181 - recall: 0.9181 - prc: 0.9605\n",
            " 30/158 [====>.........................] - ETA: 12:52 - loss: 0.2974 - accuracy: 0.9177 - precision: 0.9177 - recall: 0.9177 - prc: 0.9609\n",
            " 31/158 [====>.........................] - ETA: 12:46 - loss: 0.2977 - accuracy: 0.9163 - precision: 0.9163 - recall: 0.9163 - prc: 0.9607\n",
            " 32/158 [=====>........................] - ETA: 12:40 - loss: 0.2990 - accuracy: 0.9102 - precision: 0.9102 - recall: 0.9102 - prc: 0.9577\n",
            " 33/158 [=====>........................] - ETA: 12:34 - loss: 0.3058 - accuracy: 0.9081 - precision: 0.9081 - recall: 0.9081 - prc: 0.9557\n",
            " 34/158 [=====>........................] - ETA: 12:28 - loss: 0.3087 - accuracy: 0.9026 - precision: 0.9026 - recall: 0.9026 - prc: 0.9524\n",
            " 35/158 [=====>........................] - ETA: 12:22 - loss: 0.3106 - accuracy: 0.9027 - precision: 0.9027 - recall: 0.9027 - prc: 0.9522\n",
            " 36/158 [=====>........................] - ETA: 12:16 - loss: 0.3133 - accuracy: 0.8967 - precision: 0.8967 - recall: 0.8967 - prc: 0.9498\n",
            " 37/158 [======>.......................] - ETA: 12:10 - loss: 0.3153 - accuracy: 0.8944 - precision: 0.8944 - recall: 0.8944 - prc: 0.9483\n",
            " 38/158 [======>.......................] - ETA: 12:04 - loss: 0.3131 - accuracy: 0.8939 - precision: 0.8939 - recall: 0.8939 - prc: 0.9484\n",
            " 39/158 [======>.......................] - ETA: 11:58 - loss: 0.3109 - accuracy: 0.8926 - precision: 0.8926 - recall: 0.8926 - prc: 0.9486\n",
            " 40/158 [======>.......................] - ETA: 11:52 - loss: 0.3071 - accuracy: 0.8953 - precision: 0.8953 - recall: 0.8953 - prc: 0.9505\n",
            " 41/158 [======>.......................] - ETA: 11:46 - loss: 0.3052 - accuracy: 0.8979 - precision: 0.8979 - recall: 0.8979 - prc: 0.9521\n",
            " 42/158 [======>.......................] - ETA: 11:40 - loss: 0.3018 - accuracy: 0.9003 - precision: 0.9003 - recall: 0.9003 - prc: 0.9538\n",
            " 43/158 [=======>......................] - ETA: 11:34 - loss: 0.2975 - accuracy: 0.9026 - precision: 0.9026 - recall: 0.9026 - prc: 0.9555\n",
            " 44/158 [=======>......................] - ETA: 11:28 - loss: 0.3046 - accuracy: 0.9027 - precision: 0.9027 - recall: 0.9027 - prc: 0.9540\n",
            " 45/158 [=======>......................] - ETA: 11:22 - loss: 0.3031 - accuracy: 0.9028 - precision: 0.9028 - recall: 0.9028 - prc: 0.9542\n",
            " 46/158 [=======>......................] - ETA: 11:16 - loss: 0.3061 - accuracy: 0.9015 - precision: 0.9015 - recall: 0.9015 - prc: 0.9531\n",
            " 47/158 [=======>......................] - ETA: 11:10 - loss: 0.3038 - accuracy: 0.9029 - precision: 0.9029 - recall: 0.9029 - prc: 0.9541\n",
            " 48/158 [========>.....................] - ETA: 11:04 - loss: 0.3024 - accuracy: 0.9043 - precision: 0.9043 - recall: 0.9043 - prc: 0.9549\n",
            " 49/158 [========>.....................] - ETA: 10:58 - loss: 0.3029 - accuracy: 0.9018 - precision: 0.9018 - recall: 0.9018 - prc: 0.9542\n",
            " 50/158 [========>.....................] - ETA: 10:52 - loss: 0.3015 - accuracy: 0.9031 - precision: 0.9031 - recall: 0.9031 - prc: 0.9550\n",
            " 51/158 [========>.....................] - ETA: 10:46 - loss: 0.3019 - accuracy: 0.9020 - precision: 0.9020 - recall: 0.9020 - prc: 0.9545\n",
            " 52/158 [========>.....................] - ETA: 10:40 - loss: 0.3010 - accuracy: 0.9020 - precision: 0.9020 - recall: 0.9020 - prc: 0.9547\n",
            " 53/158 [=========>....................] - ETA: 10:34 - loss: 0.3023 - accuracy: 0.9009 - precision: 0.9009 - recall: 0.9009 - prc: 0.9541\n",
            " 54/158 [=========>....................] - ETA: 10:28 - loss: 0.3011 - accuracy: 0.8999 - precision: 0.8999 - recall: 0.8999 - prc: 0.9538\n",
            " 55/158 [=========>....................] - ETA: 10:22 - loss: 0.2994 - accuracy: 0.9011 - precision: 0.9011 - recall: 0.9011 - prc: 0.9546\n",
            " 56/158 [=========>....................] - ETA: 10:16 - loss: 0.2985 - accuracy: 0.9029 - precision: 0.9029 - recall: 0.9029 - prc: 0.9556\n",
            " 57/158 [=========>....................] - ETA: 10:09 - loss: 0.2971 - accuracy: 0.9041 - precision: 0.9041 - recall: 0.9041 - prc: 0.9564\n",
            " 58/158 [==========>...................] - ETA: 10:03 - loss: 0.2947 - accuracy: 0.9057 - precision: 0.9057 - recall: 0.9057 - prc: 0.9576\n",
            " 59/158 [==========>...................] - ETA: 9:57 - loss: 0.2949 - accuracy: 0.9057 - precision: 0.9057 - recall: 0.9057 - prc: 0.9576 \n",
            " 60/158 [==========>...................] - ETA: 9:51 - loss: 0.2952 - accuracy: 0.9042 - precision: 0.9042 - recall: 0.9042 - prc: 0.9568\n",
            " 61/158 [==========>...................] - ETA: 9:45 - loss: 0.2954 - accuracy: 0.9037 - precision: 0.9037 - recall: 0.9037 - prc: 0.9566\n",
            " 62/158 [==========>...................] - ETA: 9:39 - loss: 0.2937 - accuracy: 0.9042 - precision: 0.9042 - recall: 0.9042 - prc: 0.9571\n",
            " 63/158 [==========>...................] - ETA: 9:33 - loss: 0.2916 - accuracy: 0.9053 - precision: 0.9053 - recall: 0.9053 - prc: 0.9578\n",
            " 64/158 [===========>..................] - ETA: 9:27 - loss: 0.2908 - accuracy: 0.9062 - precision: 0.9062 - recall: 0.9062 - prc: 0.9585\n",
            " 65/158 [===========>..................] - ETA: 9:21 - loss: 0.2883 - accuracy: 0.9072 - precision: 0.9072 - recall: 0.9072 - prc: 0.9592\n",
            " 66/158 [===========>..................] - ETA: 9:15 - loss: 0.2866 - accuracy: 0.9081 - precision: 0.9081 - recall: 0.9081 - prc: 0.9599\n",
            " 67/158 [===========>..................] - ETA: 9:09 - loss: 0.2861 - accuracy: 0.9090 - precision: 0.9090 - recall: 0.9090 - prc: 0.9604\n",
            " 68/158 [===========>..................] - ETA: 9:03 - loss: 0.2833 - accuracy: 0.9104 - precision: 0.9104 - recall: 0.9104 - prc: 0.9614\n",
            " 69/158 [============>.................] - ETA: 8:56 - loss: 0.2817 - accuracy: 0.9112 - precision: 0.9112 - recall: 0.9112 - prc: 0.9622\n",
            " 70/158 [============>.................] - ETA: 8:50 - loss: 0.2825 - accuracy: 0.9112 - precision: 0.9112 - recall: 0.9112 - prc: 0.9620\n",
            " 71/158 [============>.................] - ETA: 8:44 - loss: 0.2870 - accuracy: 0.9093 - precision: 0.9093 - recall: 0.9093 - prc: 0.9604\n",
            " 72/158 [============>.................] - ETA: 8:38 - loss: 0.2864 - accuracy: 0.9102 - precision: 0.9102 - recall: 0.9102 - prc: 0.9609\n",
            " 73/158 [============>.................] - ETA: 8:32 - loss: 0.2851 - accuracy: 0.9110 - precision: 0.9110 - recall: 0.9110 - prc: 0.9615\n",
            " 74/158 [=============>................] - ETA: 8:26 - loss: 0.2863 - accuracy: 0.9096 - precision: 0.9096 - recall: 0.9096 - prc: 0.9609\n",
            " 75/158 [=============>................] - ETA: 8:20 - loss: 0.2861 - accuracy: 0.9096 - precision: 0.9096 - recall: 0.9096 - prc: 0.9608\n",
            " 76/158 [=============>................] - ETA: 8:14 - loss: 0.2850 - accuracy: 0.9104 - precision: 0.9104 - recall: 0.9104 - prc: 0.9613\n",
            " 77/158 [=============>................] - ETA: 8:08 - loss: 0.2851 - accuracy: 0.9107 - precision: 0.9107 - recall: 0.9107 - prc: 0.9614\n",
            " 78/158 [=============>................] - ETA: 8:02 - loss: 0.2855 - accuracy: 0.9103 - precision: 0.9103 - recall: 0.9103 - prc: 0.9611\n",
            " 79/158 [==============>...............] - ETA: 7:56 - loss: 0.2842 - accuracy: 0.9114 - precision: 0.9114 - recall: 0.9114 - prc: 0.9617\n",
            " 80/158 [==============>...............] - ETA: 7:50 - loss: 0.2843 - accuracy: 0.9117 - precision: 0.9117 - recall: 0.9117 - prc: 0.9619\n",
            " 81/158 [==============>...............] - ETA: 7:44 - loss: 0.2851 - accuracy: 0.9109 - precision: 0.9109 - recall: 0.9109 - prc: 0.9614\n",
            " 82/158 [==============>...............] - ETA: 7:38 - loss: 0.2857 - accuracy: 0.9101 - precision: 0.9101 - recall: 0.9101 - prc: 0.9609\n",
            " 83/158 [==============>...............] - ETA: 7:32 - loss: 0.2842 - accuracy: 0.9100 - precision: 0.9100 - recall: 0.9100 - prc: 0.9612\n",
            " 84/158 [==============>...............] - ETA: 7:26 - loss: 0.2836 - accuracy: 0.9103 - precision: 0.9103 - recall: 0.9103 - prc: 0.9616\n",
            " 85/158 [===============>..............] - ETA: 7:20 - loss: 0.2828 - accuracy: 0.9107 - precision: 0.9107 - recall: 0.9107 - prc: 0.9618\n",
            " 86/158 [===============>..............] - ETA: 7:14 - loss: 0.2823 - accuracy: 0.9106 - precision: 0.9106 - recall: 0.9106 - prc: 0.9618\n",
            " 87/158 [===============>..............] - ETA: 7:07 - loss: 0.2803 - accuracy: 0.9116 - precision: 0.9116 - recall: 0.9116 - prc: 0.9625\n",
            " 88/158 [===============>..............] - ETA: 7:01 - loss: 0.2794 - accuracy: 0.9123 - precision: 0.9123 - recall: 0.9123 - prc: 0.9629\n",
            " 89/158 [===============>..............] - ETA: 6:55 - loss: 0.2774 - accuracy: 0.9133 - precision: 0.9133 - recall: 0.9133 - prc: 0.9636\n",
            " 90/158 [================>.............] - ETA: 6:50 - loss: 0.2770 - accuracy: 0.9132 - precision: 0.9132 - recall: 0.9132 - prc: 0.9636\n",
            " 91/158 [================>.............] - ETA: 6:43 - loss: 0.2760 - accuracy: 0.9135 - precision: 0.9135 - recall: 0.9135 - prc: 0.9639\n",
            " 92/158 [================>.............] - ETA: 6:37 - loss: 0.2763 - accuracy: 0.9141 - precision: 0.9141 - recall: 0.9141 - prc: 0.9641\n",
            " 93/158 [================>.............] - ETA: 6:31 - loss: 0.2783 - accuracy: 0.9136 - precision: 0.9136 - recall: 0.9136 - prc: 0.9636\n",
            " 94/158 [================>.............] - ETA: 6:25 - loss: 0.2782 - accuracy: 0.9142 - precision: 0.9142 - recall: 0.9142 - prc: 0.9638\n",
            " 95/158 [=================>............] - ETA: 6:19 - loss: 0.2772 - accuracy: 0.9148 - precision: 0.9148 - recall: 0.9148 - prc: 0.9642\n",
            " 96/158 [=================>............] - ETA: 6:13 - loss: 0.2773 - accuracy: 0.9144 - precision: 0.9144 - recall: 0.9144 - prc: 0.9639\n",
            " 97/158 [=================>............] - ETA: 6:07 - loss: 0.2768 - accuracy: 0.9146 - precision: 0.9146 - recall: 0.9146 - prc: 0.9641\n",
            " 98/158 [=================>............] - ETA: 6:01 - loss: 0.2763 - accuracy: 0.9149 - precision: 0.9149 - recall: 0.9149 - prc: 0.9642\n",
            " 99/158 [=================>............] - ETA: 5:55 - loss: 0.2755 - accuracy: 0.9157 - precision: 0.9157 - recall: 0.9157 - prc: 0.9647\n",
            "100/158 [=================>............] - ETA: 5:49 - loss: 0.2743 - accuracy: 0.9166 - precision: 0.9166 - recall: 0.9166 - prc: 0.9652\n",
            "101/158 [==================>...........] - ETA: 5:43 - loss: 0.2734 - accuracy: 0.9171 - precision: 0.9171 - recall: 0.9171 - prc: 0.9655\n",
            "102/158 [==================>...........] - ETA: 5:37 - loss: 0.2736 - accuracy: 0.9176 - precision: 0.9176 - recall: 0.9176 - prc: 0.9656\n",
            "103/158 [==================>...........] - ETA: 5:31 - loss: 0.2728 - accuracy: 0.9178 - precision: 0.9178 - recall: 0.9178 - prc: 0.9658\n",
            "104/158 [==================>...........] - ETA: 5:25 - loss: 0.2719 - accuracy: 0.9186 - precision: 0.9186 - recall: 0.9186 - prc: 0.9662\n",
            "105/158 [==================>...........] - ETA: 5:19 - loss: 0.2714 - accuracy: 0.9190 - precision: 0.9190 - recall: 0.9190 - prc: 0.9665\n",
            "106/158 [===================>..........] - ETA: 5:13 - loss: 0.2715 - accuracy: 0.9189 - precision: 0.9189 - recall: 0.9189 - prc: 0.9663\n",
            "107/158 [===================>..........] - ETA: 5:07 - loss: 0.2721 - accuracy: 0.9188 - precision: 0.9188 - recall: 0.9188 - prc: 0.9662\n",
            "108/158 [===================>..........] - ETA: 5:01 - loss: 0.2726 - accuracy: 0.9187 - precision: 0.9187 - recall: 0.9187 - prc: 0.9660\n",
            "109/158 [===================>..........] - ETA: 4:55 - loss: 0.2722 - accuracy: 0.9192 - precision: 0.9192 - recall: 0.9192 - prc: 0.9663\n",
            "110/158 [===================>..........] - ETA: 4:49 - loss: 0.2706 - accuracy: 0.9199 - precision: 0.9199 - recall: 0.9199 - prc: 0.9668\n",
            "111/158 [====================>.........] - ETA: 4:43 - loss: 0.2696 - accuracy: 0.9203 - precision: 0.9203 - recall: 0.9203 - prc: 0.9670\n",
            "112/158 [====================>.........] - ETA: 4:37 - loss: 0.2690 - accuracy: 0.9202 - precision: 0.9202 - recall: 0.9202 - prc: 0.9670\n",
            "113/158 [====================>.........] - ETA: 4:31 - loss: 0.2681 - accuracy: 0.9209 - precision: 0.9209 - recall: 0.9209 - prc: 0.9675\n",
            "114/158 [====================>.........] - ETA: 4:25 - loss: 0.2676 - accuracy: 0.9208 - precision: 0.9208 - recall: 0.9208 - prc: 0.9675\n",
            "115/158 [====================>.........] - ETA: 4:19 - loss: 0.2683 - accuracy: 0.9204 - precision: 0.9204 - recall: 0.9204 - prc: 0.9674\n",
            "116/158 [=====================>........] - ETA: 4:13 - loss: 0.2680 - accuracy: 0.9208 - precision: 0.9208 - recall: 0.9208 - prc: 0.9675\n",
            "117/158 [=====================>........] - ETA: 4:07 - loss: 0.2683 - accuracy: 0.9207 - precision: 0.9207 - recall: 0.9207 - prc: 0.9675\n",
            "118/158 [=====================>........] - ETA: 4:01 - loss: 0.2683 - accuracy: 0.9211 - precision: 0.9211 - recall: 0.9211 - prc: 0.9677\n",
            "119/158 [=====================>........] - ETA: 3:55 - loss: 0.2681 - accuracy: 0.9215 - precision: 0.9215 - recall: 0.9215 - prc: 0.9680\n",
            "120/158 [=====================>........] - ETA: 3:49 - loss: 0.2677 - accuracy: 0.9216 - precision: 0.9216 - recall: 0.9216 - prc: 0.9681\n",
            "121/158 [=====================>........] - ETA: 3:43 - loss: 0.2677 - accuracy: 0.9220 - precision: 0.9220 - recall: 0.9220 - prc: 0.9682\n",
            "122/158 [======================>.......] - ETA: 3:36 - loss: 0.2672 - accuracy: 0.9224 - precision: 0.9224 - recall: 0.9224 - prc: 0.9684\n",
            "123/158 [======================>.......] - ETA: 3:30 - loss: 0.2665 - accuracy: 0.9228 - precision: 0.9228 - recall: 0.9228 - prc: 0.9687\n",
            "124/158 [======================>.......] - ETA: 3:24 - loss: 0.2658 - accuracy: 0.9234 - precision: 0.9234 - recall: 0.9234 - prc: 0.9690\n",
            "125/158 [======================>.......] - ETA: 3:18 - loss: 0.2648 - accuracy: 0.9235 - precision: 0.9235 - recall: 0.9235 - prc: 0.9691\n",
            "126/158 [======================>.......] - ETA: 3:12 - loss: 0.2644 - accuracy: 0.9241 - precision: 0.9241 - recall: 0.9241 - prc: 0.9694\n",
            "127/158 [=======================>......] - ETA: 3:06 - loss: 0.2637 - accuracy: 0.9242 - precision: 0.9242 - recall: 0.9242 - prc: 0.9695\n",
            "128/158 [=======================>......] - ETA: 3:00 - loss: 0.2627 - accuracy: 0.9248 - precision: 0.9248 - recall: 0.9248 - prc: 0.9699\n",
            "129/158 [=======================>......] - ETA: 2:54 - loss: 0.2620 - accuracy: 0.9252 - precision: 0.9252 - recall: 0.9252 - prc: 0.9701\n",
            "130/158 [=======================>......] - ETA: 2:48 - loss: 0.2611 - accuracy: 0.9257 - precision: 0.9257 - recall: 0.9257 - prc: 0.9704\n",
            "131/158 [=======================>......] - ETA: 2:42 - loss: 0.2614 - accuracy: 0.9258 - precision: 0.9258 - recall: 0.9258 - prc: 0.9704\n",
            "132/158 [========================>.....] - ETA: 2:36 - loss: 0.2620 - accuracy: 0.9261 - precision: 0.9261 - recall: 0.9261 - prc: 0.9704\n",
            "133/158 [========================>.....] - ETA: 2:30 - loss: 0.2615 - accuracy: 0.9262 - precision: 0.9262 - recall: 0.9262 - prc: 0.9704\n",
            "134/158 [========================>.....] - ETA: 2:24 - loss: 0.2609 - accuracy: 0.9265 - precision: 0.9265 - recall: 0.9265 - prc: 0.9707\n",
            "135/158 [========================>.....] - ETA: 2:18 - loss: 0.2608 - accuracy: 0.9271 - precision: 0.9271 - recall: 0.9271 - prc: 0.9710\n",
            "136/158 [========================>.....] - ETA: 2:12 - loss: 0.2600 - accuracy: 0.9274 - precision: 0.9274 - recall: 0.9274 - prc: 0.9712\n",
            "137/158 [=========================>....] - ETA: 2:06 - loss: 0.2605 - accuracy: 0.9277 - precision: 0.9277 - recall: 0.9277 - prc: 0.9712\n",
            "138/158 [=========================>....] - ETA: 2:00 - loss: 0.2604 - accuracy: 0.9278 - precision: 0.9278 - recall: 0.9278 - prc: 0.9712\n",
            "139/158 [=========================>....] - ETA: 1:54 - loss: 0.2605 - accuracy: 0.9274 - precision: 0.9274 - recall: 0.9274 - prc: 0.9710\n",
            "140/158 [=========================>....] - ETA: 1:48 - loss: 0.2608 - accuracy: 0.9270 - precision: 0.9270 - recall: 0.9270 - prc: 0.9708\n",
            "141/158 [=========================>....] - ETA: 1:42 - loss: 0.2602 - accuracy: 0.9267 - precision: 0.9267 - recall: 0.9267 - prc: 0.9707\n",
            "142/158 [=========================>....] - ETA: 1:36 - loss: 0.2599 - accuracy: 0.9267 - precision: 0.9267 - recall: 0.9267 - prc: 0.9708\n",
            "143/158 [==========================>...] - ETA: 1:30 - loss: 0.2598 - accuracy: 0.9266 - precision: 0.9266 - recall: 0.9266 - prc: 0.9707\n",
            "144/158 [==========================>...] - ETA: 1:24 - loss: 0.2596 - accuracy: 0.9267 - precision: 0.9267 - recall: 0.9267 - prc: 0.9708\n",
            "145/158 [==========================>...] - ETA: 1:18 - loss: 0.2594 - accuracy: 0.9272 - precision: 0.9272 - recall: 0.9272 - prc: 0.9710\n",
            "146/158 [==========================>...] - ETA: 1:12 - loss: 0.2593 - accuracy: 0.9275 - precision: 0.9275 - recall: 0.9275 - prc: 0.9711\n",
            "147/158 [==========================>...] - ETA: 1:06 - loss: 0.2593 - accuracy: 0.9277 - precision: 0.9277 - recall: 0.9277 - prc: 0.9712\n",
            "148/158 [===========================>..] - ETA: 1:00 - loss: 0.2589 - accuracy: 0.9276 - precision: 0.9276 - recall: 0.9276 - prc: 0.9712\n",
            "149/158 [===========================>..] - ETA: 54s - loss: 0.2590 - accuracy: 0.9279 - precision: 0.9279 - recall: 0.9279 - prc: 0.9713 \n",
            "150/158 [===========================>..] - ETA: 48s - loss: 0.2589 - accuracy: 0.9281 - precision: 0.9281 - recall: 0.9281 - prc: 0.9714\n",
            "151/158 [===========================>..] - ETA: 42s - loss: 0.2588 - accuracy: 0.9282 - precision: 0.9282 - recall: 0.9282 - prc: 0.9715\n",
            "152/158 [===========================>..] - ETA: 36s - loss: 0.2583 - accuracy: 0.9285 - precision: 0.9285 - recall: 0.9285 - prc: 0.9716\n",
            "153/158 [============================>.] - ETA: 30s - loss: 0.2585 - accuracy: 0.9285 - precision: 0.9285 - recall: 0.9285 - prc: 0.9716\n",
            "154/158 [============================>.] - ETA: 24s - loss: 0.2589 - accuracy: 0.9282 - precision: 0.9282 - recall: 0.9282 - prc: 0.9713\n",
            "155/158 [============================>.] - ETA: 18s - loss: 0.2603 - accuracy: 0.9278 - precision: 0.9278 - recall: 0.9278 - prc: 0.9707\n",
            "156/158 [============================>.] - ETA: 12s - loss: 0.2597 - accuracy: 0.9279 - precision: 0.9279 - recall: 0.9279 - prc: 0.9708\n",
            "157/158 [============================>.] - ETA: 6s - loss: 0.2595 - accuracy: 0.9282 - precision: 0.9282 - recall: 0.9282 - prc: 0.9709 \n",
            "158/158 [==============================] - ETA: 0s - loss: 0.2587 - accuracy: 0.9284 - precision: 0.9284 - recall: 0.9284 - prc: 0.9711\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(pid=5224)\u001b[0m 2022-02-10 13:03:09.542188: W tensorflow/core/framework/dataset.cc:744] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(pid=5224)\u001b[0m \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r158/158 [==============================] - 953s 6s/step - loss: 0.2587 - accuracy: 0.9284 - precision: 0.9284 - recall: 0.9284 - prc: 0.9711 - val_loss: 0.2499 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_prc: 1.0000\n",
            "\u001b[2m\u001b[36m(pid=5224)\u001b[0m Epoch 3/3\n",
            "  1/158 [..............................] - ETA: 18:32 - loss: 0.1764 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - prc: 1.0000\n",
            "  2/158 [..............................] - ETA: 15:49 - loss: 0.2242 - accuracy: 0.9688 - precision: 0.9688 - recall: 0.9688 - prc: 0.9807\n",
            "  3/158 [..............................] - ETA: 15:42 - loss: 0.2216 - accuracy: 0.9688 - precision: 0.9688 - recall: 0.9688 - prc: 0.9841\n",
            "  4/158 [..............................] - ETA: 15:38 - loss: 0.2464 - accuracy: 0.9453 - precision: 0.9453 - recall: 0.9453 - prc: 0.9771\n",
            "  5/158 [..............................] - ETA: 15:31 - loss: 0.2336 - accuracy: 0.9563 - precision: 0.9563 - recall: 0.9563 - prc: 0.9823\n",
            "  6/158 [>.............................] - ETA: 15:25 - loss: 0.2506 - accuracy: 0.9375 - precision: 0.9375 - recall: 0.9375 - prc: 0.9745\n",
            "  7/158 [>.............................] - ETA: 15:18 - loss: 0.2540 - accuracy: 0.9286 - precision: 0.9286 - recall: 0.9286 - prc: 0.9733\n",
            "  8/158 [>.............................] - ETA: 15:13 - loss: 0.2583 - accuracy: 0.9297 - precision: 0.9297 - recall: 0.9297 - prc: 0.9725\n",
            "  9/158 [>.............................] - ETA: 15:07 - loss: 0.2542 - accuracy: 0.9306 - precision: 0.9306 - recall: 0.9306 - prc: 0.9744\n",
            " 10/158 [>.............................] - ETA: 15:02 - loss: 0.2531 - accuracy: 0.9312 - precision: 0.9312 - recall: 0.9312 - prc: 0.9744\n",
            " 11/158 [=>............................] - ETA: 14:55 - loss: 0.2575 - accuracy: 0.9290 - precision: 0.9290 - recall: 0.9290 - prc: 0.9730\n",
            " 12/158 [=>............................] - ETA: 14:49 - loss: 0.2556 - accuracy: 0.9323 - precision: 0.9323 - recall: 0.9323 - prc: 0.9739\n",
            " 13/158 [=>............................] - ETA: 14:42 - loss: 0.2517 - accuracy: 0.9327 - precision: 0.9327 - recall: 0.9327 - prc: 0.9737\n",
            " 14/158 [=>............................] - ETA: 14:37 - loss: 0.2448 - accuracy: 0.9353 - precision: 0.9353 - recall: 0.9353 - prc: 0.9754\n",
            " 15/158 [=>............................] - ETA: 14:32 - loss: 0.2431 - accuracy: 0.9375 - precision: 0.9375 - recall: 0.9375 - prc: 0.9724\n",
            " 16/158 [==>...........................] - ETA: 14:25 - loss: 0.2356 - accuracy: 0.9414 - precision: 0.9414 - recall: 0.9414 - prc: 0.9747\n",
            " 17/158 [==>...........................] - ETA: 14:19 - loss: 0.2338 - accuracy: 0.9430 - precision: 0.9430 - recall: 0.9430 - prc: 0.9762\n",
            " 18/158 [==>...........................] - ETA: 14:13 - loss: 0.2322 - accuracy: 0.9427 - precision: 0.9427 - recall: 0.9427 - prc: 0.9765\n",
            " 19/158 [==>...........................] - ETA: 14:07 - loss: 0.2328 - accuracy: 0.9391 - precision: 0.9391 - recall: 0.9391 - prc: 0.9750\n",
            " 20/158 [==>...........................] - ETA: 14:00 - loss: 0.2318 - accuracy: 0.9406 - precision: 0.9406 - recall: 0.9406 - prc: 0.9757\n",
            " 21/158 [==>...........................] - ETA: 13:54 - loss: 0.2294 - accuracy: 0.9420 - precision: 0.9420 - recall: 0.9420 - prc: 0.9763\n",
            " 22/158 [===>..........................] - ETA: 13:47 - loss: 0.2248 - accuracy: 0.9432 - precision: 0.9432 - recall: 0.9432 - prc: 0.9773\n",
            " 23/158 [===>..........................] - ETA: 13:41 - loss: 0.2173 - accuracy: 0.9457 - precision: 0.9457 - recall: 0.9457 - prc: 0.9789\n",
            " 24/158 [===>..........................] - ETA: 13:35 - loss: 0.2121 - accuracy: 0.9479 - precision: 0.9479 - recall: 0.9479 - prc: 0.9803\n",
            " 25/158 [===>..........................] - ETA: 13:29 - loss: 0.2077 - accuracy: 0.9500 - precision: 0.9500 - recall: 0.9500 - prc: 0.9815\n",
            " 26/158 [===>..........................] - ETA: 13:24 - loss: 0.2065 - accuracy: 0.9507 - precision: 0.9507 - recall: 0.9507 - prc: 0.9815\n",
            " 27/158 [====>.........................] - ETA: 13:17 - loss: 0.2061 - accuracy: 0.9525 - precision: 0.9525 - recall: 0.9525 - prc: 0.9822\n",
            " 28/158 [====>.........................] - ETA: 13:12 - loss: 0.2101 - accuracy: 0.9509 - precision: 0.9509 - recall: 0.9509 - prc: 0.9813\n",
            " 29/158 [====>.........................] - ETA: 13:06 - loss: 0.2092 - accuracy: 0.9526 - precision: 0.9526 - recall: 0.9526 - prc: 0.9820\n",
            " 30/158 [====>.........................] - ETA: 13:00 - loss: 0.2103 - accuracy: 0.9531 - precision: 0.9531 - recall: 0.9531 - prc: 0.9818\n",
            " 31/158 [====>.........................] - ETA: 12:54 - loss: 0.2169 - accuracy: 0.9526 - precision: 0.9526 - recall: 0.9526 - prc: 0.9806\n",
            " 32/158 [=====>........................] - ETA: 12:47 - loss: 0.2190 - accuracy: 0.9521 - precision: 0.9521 - recall: 0.9521 - prc: 0.9800\n",
            " 33/158 [=====>........................] - ETA: 12:41 - loss: 0.2166 - accuracy: 0.9536 - precision: 0.9536 - recall: 0.9536 - prc: 0.9808\n",
            " 34/158 [=====>........................] - ETA: 12:35 - loss: 0.2146 - accuracy: 0.9550 - precision: 0.9550 - recall: 0.9550 - prc: 0.9815\n",
            " 35/158 [=====>........................] - ETA: 12:29 - loss: 0.2166 - accuracy: 0.9527 - precision: 0.9527 - recall: 0.9527 - prc: 0.9807\n",
            " 36/158 [=====>........................] - ETA: 12:23 - loss: 0.2146 - accuracy: 0.9540 - precision: 0.9540 - recall: 0.9540 - prc: 0.9813\n",
            " 37/158 [======>.......................] - ETA: 12:16 - loss: 0.2175 - accuracy: 0.9519 - precision: 0.9519 - recall: 0.9519 - prc: 0.9801\n",
            " 38/158 [======>.......................] - ETA: 12:10 - loss: 0.2194 - accuracy: 0.9515 - precision: 0.9515 - recall: 0.9515 - prc: 0.9800\n",
            " 39/158 [======>.......................] - ETA: 12:03 - loss: 0.2190 - accuracy: 0.9519 - precision: 0.9519 - recall: 0.9519 - prc: 0.9802\n",
            " 40/158 [======>.......................] - ETA: 11:57 - loss: 0.2182 - accuracy: 0.9523 - precision: 0.9523 - recall: 0.9523 - prc: 0.9804\n",
            " 41/158 [======>.......................] - ETA: 11:51 - loss: 0.2175 - accuracy: 0.9527 - precision: 0.9527 - recall: 0.9527 - prc: 0.9809\n",
            " 42/158 [======>.......................] - ETA: 11:45 - loss: 0.2155 - accuracy: 0.9539 - precision: 0.9539 - recall: 0.9539 - prc: 0.9815\n",
            " 43/158 [=======>......................] - ETA: 11:38 - loss: 0.2156 - accuracy: 0.9535 - precision: 0.9535 - recall: 0.9535 - prc: 0.9813\n",
            " 44/158 [=======>......................] - ETA: 11:32 - loss: 0.2135 - accuracy: 0.9531 - precision: 0.9531 - recall: 0.9531 - prc: 0.9813\n",
            " 45/158 [=======>......................] - ETA: 11:26 - loss: 0.2172 - accuracy: 0.9514 - precision: 0.9514 - recall: 0.9514 - prc: 0.9800\n",
            " 46/158 [=======>......................] - ETA: 11:20 - loss: 0.2152 - accuracy: 0.9511 - precision: 0.9511 - recall: 0.9511 - prc: 0.9800\n",
            " 47/158 [=======>......................] - ETA: 11:14 - loss: 0.2166 - accuracy: 0.9501 - precision: 0.9501 - recall: 0.9501 - prc: 0.9798\n",
            " 48/158 [========>.....................] - ETA: 11:07 - loss: 0.2145 - accuracy: 0.9512 - precision: 0.9512 - recall: 0.9512 - prc: 0.9804\n",
            " 49/158 [========>.....................] - ETA: 11:01 - loss: 0.2134 - accuracy: 0.9509 - precision: 0.9509 - recall: 0.9509 - prc: 0.9803\n",
            " 50/158 [========>.....................] - ETA: 10:55 - loss: 0.2124 - accuracy: 0.9519 - precision: 0.9519 - recall: 0.9519 - prc: 0.9807\n",
            " 51/158 [========>.....................] - ETA: 10:49 - loss: 0.2124 - accuracy: 0.9522 - precision: 0.9522 - recall: 0.9522 - prc: 0.9808\n",
            " 52/158 [========>.....................] - ETA: 10:43 - loss: 0.2117 - accuracy: 0.9525 - precision: 0.9525 - recall: 0.9525 - prc: 0.9810\n",
            " 53/158 [=========>....................] - ETA: 10:37 - loss: 0.2116 - accuracy: 0.9528 - precision: 0.9528 - recall: 0.9528 - prc: 0.9811\n",
            " 54/158 [=========>....................] - ETA: 10:31 - loss: 0.2099 - accuracy: 0.9531 - precision: 0.9531 - recall: 0.9531 - prc: 0.9813\n",
            " 55/158 [=========>....................] - ETA: 10:25 - loss: 0.2108 - accuracy: 0.9540 - precision: 0.9540 - recall: 0.9540 - prc: 0.9816\n",
            " 56/158 [=========>....................] - ETA: 10:19 - loss: 0.2116 - accuracy: 0.9548 - precision: 0.9548 - recall: 0.9548 - prc: 0.9819\n",
            " 57/158 [=========>....................] - ETA: 10:13 - loss: 0.2115 - accuracy: 0.9539 - precision: 0.9539 - recall: 0.9539 - prc: 0.9817\n",
            " 58/158 [==========>...................] - ETA: 10:07 - loss: 0.2115 - accuracy: 0.9542 - precision: 0.9542 - recall: 0.9542 - prc: 0.9818\n",
            " 59/158 [==========>...................] - ETA: 10:00 - loss: 0.2116 - accuracy: 0.9544 - precision: 0.9544 - recall: 0.9544 - prc: 0.9818\n",
            " 60/158 [==========>...................] - ETA: 9:54 - loss: 0.2108 - accuracy: 0.9536 - precision: 0.9536 - recall: 0.9536 - prc: 0.9816 \n",
            " 61/158 [==========>...................] - ETA: 9:48 - loss: 0.2091 - accuracy: 0.9544 - precision: 0.9544 - recall: 0.9544 - prc: 0.9821\n",
            " 62/158 [==========>...................] - ETA: 9:42 - loss: 0.2092 - accuracy: 0.9551 - precision: 0.9551 - recall: 0.9551 - prc: 0.9823\n",
            " 63/158 [==========>...................] - ETA: 9:36 - loss: 0.2087 - accuracy: 0.9549 - precision: 0.9549 - recall: 0.9549 - prc: 0.9824\n",
            " 64/158 [===========>..................] - ETA: 9:30 - loss: 0.2070 - accuracy: 0.9546 - precision: 0.9546 - recall: 0.9546 - prc: 0.9824\n",
            " 65/158 [===========>..................] - ETA: 9:24 - loss: 0.2061 - accuracy: 0.9553 - precision: 0.9553 - recall: 0.9553 - prc: 0.9828\n",
            " 66/158 [===========>..................] - ETA: 9:18 - loss: 0.2061 - accuracy: 0.9560 - precision: 0.9560 - recall: 0.9560 - prc: 0.9830\n",
            " 67/158 [===========>..................] - ETA: 9:11 - loss: 0.2060 - accuracy: 0.9557 - precision: 0.9557 - recall: 0.9557 - prc: 0.9831\n",
            " 68/158 [===========>..................] - ETA: 9:05 - loss: 0.2060 - accuracy: 0.9554 - precision: 0.9554 - recall: 0.9554 - prc: 0.9829\n",
            " 69/158 [============>.................] - ETA: 8:59 - loss: 0.2041 - accuracy: 0.9561 - precision: 0.9561 - recall: 0.9561 - prc: 0.9833\n",
            " 70/158 [============>.................] - ETA: 8:53 - loss: 0.2066 - accuracy: 0.9554 - precision: 0.9554 - recall: 0.9554 - prc: 0.9824\n",
            " 71/158 [============>.................] - ETA: 8:47 - loss: 0.2061 - accuracy: 0.9555 - precision: 0.9555 - recall: 0.9555 - prc: 0.9826\n",
            " 72/158 [============>.................] - ETA: 8:41 - loss: 0.2075 - accuracy: 0.9549 - precision: 0.9549 - recall: 0.9549 - prc: 0.9823\n",
            " 73/158 [============>.................] - ETA: 8:35 - loss: 0.2081 - accuracy: 0.9538 - precision: 0.9538 - recall: 0.9538 - prc: 0.9818\n",
            " 74/158 [=============>................] - ETA: 8:29 - loss: 0.2077 - accuracy: 0.9535 - precision: 0.9535 - recall: 0.9535 - prc: 0.9819\n",
            " 75/158 [=============>................] - ETA: 8:23 - loss: 0.2079 - accuracy: 0.9529 - precision: 0.9529 - recall: 0.9529 - prc: 0.9816\n",
            " 76/158 [=============>................] - ETA: 8:17 - loss: 0.2074 - accuracy: 0.9527 - precision: 0.9527 - recall: 0.9527 - prc: 0.9815\n",
            " 77/158 [=============>................] - ETA: 8:11 - loss: 0.2073 - accuracy: 0.9525 - precision: 0.9525 - recall: 0.9525 - prc: 0.9814\n",
            " 78/158 [=============>................] - ETA: 8:05 - loss: 0.2072 - accuracy: 0.9515 - precision: 0.9515 - recall: 0.9515 - prc: 0.9811\n",
            " 79/158 [==============>...............] - ETA: 7:58 - loss: 0.2074 - accuracy: 0.9513 - precision: 0.9513 - recall: 0.9513 - prc: 0.9809\n",
            " 80/158 [==============>...............] - ETA: 7:52 - loss: 0.2072 - accuracy: 0.9516 - precision: 0.9516 - recall: 0.9516 - prc: 0.9812\n",
            " 81/158 [==============>...............] - ETA: 7:46 - loss: 0.2076 - accuracy: 0.9514 - precision: 0.9514 - recall: 0.9514 - prc: 0.9811\n",
            " 82/158 [==============>...............] - ETA: 7:40 - loss: 0.2059 - accuracy: 0.9520 - precision: 0.9520 - recall: 0.9520 - prc: 0.9815\n",
            " 83/158 [==============>...............] - ETA: 7:34 - loss: 0.2062 - accuracy: 0.9514 - precision: 0.9514 - recall: 0.9514 - prc: 0.9813\n",
            " 84/158 [==============>...............] - ETA: 7:28 - loss: 0.2064 - accuracy: 0.9509 - precision: 0.9509 - recall: 0.9509 - prc: 0.9811\n",
            " 85/158 [===============>..............] - ETA: 7:22 - loss: 0.2073 - accuracy: 0.9507 - precision: 0.9507 - recall: 0.9507 - prc: 0.9808\n",
            " 86/158 [===============>..............] - ETA: 7:16 - loss: 0.2071 - accuracy: 0.9513 - precision: 0.9513 - recall: 0.9513 - prc: 0.9811\n",
            " 87/158 [===============>..............] - ETA: 7:10 - loss: 0.2064 - accuracy: 0.9519 - precision: 0.9519 - recall: 0.9519 - prc: 0.9814\n",
            " 88/158 [===============>..............] - ETA: 7:04 - loss: 0.2069 - accuracy: 0.9517 - precision: 0.9517 - recall: 0.9517 - prc: 0.9813\n",
            " 89/158 [===============>..............] - ETA: 6:58 - loss: 0.2067 - accuracy: 0.9522 - precision: 0.9522 - recall: 0.9522 - prc: 0.9815\n",
            " 90/158 [================>.............] - ETA: 6:52 - loss: 0.2063 - accuracy: 0.9524 - precision: 0.9524 - recall: 0.9524 - prc: 0.9816\n",
            " 91/158 [================>.............] - ETA: 6:46 - loss: 0.2062 - accuracy: 0.9526 - precision: 0.9526 - recall: 0.9526 - prc: 0.9818\n",
            " 92/158 [================>.............] - ETA: 6:40 - loss: 0.2063 - accuracy: 0.9528 - precision: 0.9528 - recall: 0.9528 - prc: 0.9819\n",
            " 93/158 [================>.............] - ETA: 6:34 - loss: 0.2055 - accuracy: 0.9533 - precision: 0.9533 - recall: 0.9533 - prc: 0.9821\n",
            " 94/158 [================>.............] - ETA: 6:27 - loss: 0.2048 - accuracy: 0.9535 - precision: 0.9535 - recall: 0.9535 - prc: 0.9823\n",
            " 95/158 [=================>............] - ETA: 6:21 - loss: 0.2041 - accuracy: 0.9539 - precision: 0.9539 - recall: 0.9539 - prc: 0.9825\n",
            " 96/158 [=================>............] - ETA: 6:15 - loss: 0.2034 - accuracy: 0.9541 - precision: 0.9541 - recall: 0.9541 - prc: 0.9826\n",
            " 97/158 [=================>............] - ETA: 6:09 - loss: 0.2029 - accuracy: 0.9536 - precision: 0.9536 - recall: 0.9536 - prc: 0.9825\n",
            " 98/158 [=================>............] - ETA: 6:03 - loss: 0.2027 - accuracy: 0.9534 - precision: 0.9534 - recall: 0.9534 - prc: 0.9827\n",
            " 99/158 [=================>............] - ETA: 5:57 - loss: 0.2020 - accuracy: 0.9539 - precision: 0.9539 - recall: 0.9539 - prc: 0.9829\n",
            "100/158 [=================>............] - ETA: 5:51 - loss: 0.2008 - accuracy: 0.9544 - precision: 0.9544 - recall: 0.9544 - prc: 0.9832\n",
            "101/158 [==================>...........] - ETA: 5:45 - loss: 0.2023 - accuracy: 0.9539 - precision: 0.9539 - recall: 0.9539 - prc: 0.9829\n",
            "102/158 [==================>...........] - ETA: 5:37 - loss: 0.2026 - accuracy: 0.9539 - precision: 0.9539 - recall: 0.9539 - prc: 0.9829\n",
            "103/158 [==================>...........] - ETA: 5:31 - loss: 0.2025 - accuracy: 0.9540 - precision: 0.9540 - recall: 0.9540 - prc: 0.9829\n",
            "104/158 [==================>...........] - ETA: 5:25 - loss: 0.2029 - accuracy: 0.9541 - precision: 0.9541 - recall: 0.9541 - prc: 0.9829\n",
            "105/158 [==================>...........] - ETA: 5:19 - loss: 0.2032 - accuracy: 0.9546 - precision: 0.9546 - recall: 0.9546 - prc: 0.9831\n",
            "106/158 [===================>..........] - ETA: 5:13 - loss: 0.2044 - accuracy: 0.9541 - precision: 0.9541 - recall: 0.9541 - prc: 0.9827\n",
            "107/158 [===================>..........] - ETA: 5:07 - loss: 0.2036 - accuracy: 0.9546 - precision: 0.9546 - recall: 0.9546 - prc: 0.9829\n",
            "108/158 [===================>..........]\n",
            "\u001b[2m\u001b[36m(pid=5224)\u001b[0m  - ETA: 5:01 - loss: 0.2038 - accuracy: 0.9547 - precision: 0.9547 - recall: 0.9547 - prc: 0.9829\n",
            "109/158 [===================>..........] - ETA: 4:55 - loss: 0.2041 - accuracy: 0.9548 - precision: 0.9548 - recall: 0.9548 - prc: 0.9829\n",
            "110/158 [===================>..........] - ETA: 4:49 - loss: 0.2039 - accuracy: 0.9552 - precision: 0.9552 - recall: 0.9552 - prc: 0.9831\n",
            "111/158 [====================>.........] - ETA: 4:43 - loss: 0.2043 - accuracy: 0.9548 - precision: 0.9548 - recall: 0.9548 - prc: 0.9828\n",
            "112/158 [====================>.........] - ETA: 4:37 - loss: 0.2039 - accuracy: 0.9549 - precision: 0.9549 - recall: 0.9549 - prc: 0.9829\n",
            "113/158 [====================>.........] - ETA: 4:31 - loss: 0.2038 - accuracy: 0.9550 - precision: 0.9550 - recall: 0.9550 - prc: 0.9830\n",
            "114/158 [====================>.........] - ETA: 4:25 - loss: 0.2029 - accuracy: 0.9554 - precision: 0.9554 - recall: 0.9554 - prc: 0.9833\n",
            "115/158 [====================>.........] - ETA: 4:19 - loss: 0.2026 - accuracy: 0.9555 - precision: 0.9555 - recall: 0.9555 - prc: 0.9833\n",
            "116/158 [=====================>........] - ETA: 4:13 - loss: 0.2022 - accuracy: 0.9554 - precision: 0.9554 - recall: 0.9554 - prc: 0.9833\n",
            "117/158 [=====================>........] - ETA: 4:07 - loss: 0.2020 - accuracy: 0.9552 - precision: 0.9552 - recall: 0.9552 - prc: 0.9834\n",
            "118/158 [=====================>........] - ETA: 4:01 - loss: 0.2010 - accuracy: 0.9556 - precision: 0.9556 - recall: 0.9556 - prc: 0.9836\n",
            "119/158 [=====================>........] - ETA: 3:55 - loss: 0.2005 - accuracy: 0.9557 - precision: 0.9557 - recall: 0.9557 - prc: 0.9837\n",
            "120/158 [=====================>........] - ETA: 3:49 - loss: 0.2007 - accuracy: 0.9561 - precision: 0.9561 - recall: 0.9561 - prc: 0.9838\n",
            "121/158 [=====================>........] - ETA: 3:43 - loss: 0.2003 - accuracy: 0.9565 - precision: 0.9565 - recall: 0.9565 - prc: 0.9840\n",
            "122/158 [======================>.......] - ETA: 3:37 - loss: 0.2001 - accuracy: 0.9566 - precision: 0.9566 - recall: 0.9566 - prc: 0.9841\n",
            "123/158 [======================>.......] - ETA: 3:31 - loss: 0.1996 - accuracy: 0.9569 - precision: 0.9569 - recall: 0.9569 - prc: 0.9843\n",
            "124/158 [======================>.......] - ETA: 3:25 - loss: 0.1995 - accuracy: 0.9570 - precision: 0.9570 - recall: 0.9570 - prc: 0.9844\n",
            "125/158 [======================>.......] - ETA: 3:19 - loss: 0.1992 - accuracy: 0.9571 - precision: 0.9571 - recall: 0.9571 - prc: 0.9844\n",
            "126/158 [======================>.......] - ETA: 3:13 - loss: 0.1992 - accuracy: 0.9570 - precision: 0.9570 - recall: 0.9570 - prc: 0.9843\n",
            "127/158 [=======================>......] - ETA: 3:07 - loss: 0.2004 - accuracy: 0.9566 - precision: 0.9566 - recall: 0.9566 - prc: 0.9838\n",
            "128/158 [=======================>......] - ETA: 3:01 - loss: 0.1996 - accuracy: 0.9569 - precision: 0.9569 - recall: 0.9569 - prc: 0.9840\n",
            "129/158 [=======================>......] - ETA: 2:55 - loss: 0.1993 - accuracy: 0.9570 - precision: 0.9570 - recall: 0.9570 - prc: 0.9841\n",
            "130/158 [=======================>......] - ETA: 2:49 - loss: 0.1990 - accuracy: 0.9571 - precision: 0.9571 - recall: 0.9571 - prc: 0.9842\n",
            "131/158 [=======================>......] - ETA: 2:43 - loss: 0.1991 - accuracy: 0.9567 - precision: 0.9567 - recall: 0.9567 - prc: 0.9841\n",
            "132/158 [========================>.....] - ETA: 2:37 - loss: 0.1993 - accuracy: 0.9561 - precision: 0.9561 - recall: 0.9561 - prc: 0.9840\n",
            "133/158 [========================>.....] - ETA: 2:31 - loss: 0.1987 - accuracy: 0.9562 - precision: 0.9562 - recall: 0.9562 - prc: 0.9841\n",
            "134/158 [========================>.....] - ETA: 2:24 - loss: 0.1981 - accuracy: 0.9560 - precision: 0.9560 - recall: 0.9560 - prc: 0.9842\n",
            "135/158 [========================>.....] - ETA: 2:18 - loss: 0.1975 - accuracy: 0.9564 - precision: 0.9564 - recall: 0.9564 - prc: 0.9843\n",
            "136/158 [========================>.....] - ETA: 2:12 - loss: 0.1973 - accuracy: 0.9564 - precision: 0.9564 - recall: 0.9564 - prc: 0.9844\n",
            "137/158 [=========================>....] - ETA: 2:06 - loss: 0.1972 - accuracy: 0.9563 - precision: 0.9563 - recall: 0.9563 - prc: 0.9843\n",
            "138/158 [=========================>....] - ETA: 2:00 - loss: 0.1977 - accuracy: 0.9562 - precision: 0.9562 - recall: 0.9562 - prc: 0.9842\n",
            "139/158 [=========================>....] - ETA: 1:54 - loss: 0.1976 - accuracy: 0.9563 - precision: 0.9563 - recall: 0.9563 - prc: 0.9842\n",
            "140/158 [=========================>....] - ETA: 1:48 - loss: 0.1986 - accuracy: 0.9555 - precision: 0.9555 - recall: 0.9555 - prc: 0.9839\n",
            "141/158 [=========================>....] - ETA: 1:42 - loss: 0.1982 - accuracy: 0.9555 - precision: 0.9555 - recall: 0.9555 - prc: 0.9839\n",
            "142/158 [=========================>....] - ETA: 1:36 - loss: 0.1987 - accuracy: 0.9554 - precision: 0.9554 - recall: 0.9554 - prc: 0.9838\n",
            "143/158 [==========================>...] - ETA: 1:30 - loss: 0.1990 - accuracy: 0.9551 - precision: 0.9551 - recall: 0.9551 - prc: 0.9837\n",
            "144/158 [==========================>...] - ETA: 1:24 - loss: 0.1983 - accuracy: 0.9554 - precision: 0.9554 - recall: 0.9554 - prc: 0.9838\n",
            "145/158 [==========================>...] - ETA: 1:18 - loss: 0.1978 - accuracy: 0.9557 - precision: 0.9557 - recall: 0.9557 - prc: 0.9840\n",
            "146/158 [==========================>...] - ETA: 1:12 - loss: 0.1979 - accuracy: 0.9556 - precision: 0.9556 - recall: 0.9556 - prc: 0.9839\n",
            "147/158 [==========================>...] - ETA: 1:06 - loss: 0.1974 - accuracy: 0.9559 - precision: 0.9559 - recall: 0.9559 - prc: 0.9841\n",
            "148/158 [===========================>..] - ETA: 1:00 - loss: 0.1972 - accuracy: 0.9560 - precision: 0.9560 - recall: 0.9560 - prc: 0.9841\n",
            "149/158 [===========================>..] - ETA: 54s - loss: 0.1970 - accuracy: 0.9560 - precision: 0.9560 - recall: 0.9560 - prc: 0.9841 \n",
            "150/158 [===========================>..] - ETA: 48s - loss: 0.1968 - accuracy: 0.9563 - precision: 0.9563 - recall: 0.9563 - prc: 0.9843\n",
            "151/158 [===========================>..] - ETA: 42s - loss: 0.1963 - accuracy: 0.9564 - precision: 0.9564 - recall: 0.9564 - prc: 0.9843\n",
            "152/158 [===========================>..]\n",
            "\u001b[2m\u001b[36m(pid=5224)\u001b[0m  - ETA: 36s - loss: 0.1963 - accuracy: 0.9561 - precision: 0.9561 - recall: 0.9561 - prc: 0.9841\n",
            "153/158 [============================>.] - ETA: 30s - loss: 0.1954 - accuracy: 0.9564 - precision: 0.9564 - recall: 0.9564 - prc: 0.9843\n",
            "154/158 [============================>.] - ETA: 24s - loss: 0.1949 - accuracy: 0.9563 - precision: 0.9563 - recall: 0.9563 - prc: 0.9844\n",
            "155/158 [============================>.] - ETA: 18s - loss: 0.1960 - accuracy: 0.9557 - precision: 0.9557 - recall: 0.9557 - prc: 0.9840\n",
            "156/158 [============================>.] - ETA: 12s - loss: 0.1975 - accuracy: 0.9554 - precision: 0.9554 - recall: 0.9554 - prc: 0.9837\n",
            "157/158 [============================>.] - ETA: 6s - loss: 0.1973 - accuracy: 0.9557 - precision: 0.9557 - recall: 0.9557 - prc: 0.9838 \n",
            "158/158 [==============================] - ETA: 0s - loss: 0.1971 - accuracy: 0.9560 - precision: 0.9560 - recall: 0.9560 - prc: 0.9839\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(pid=5224)\u001b[0m 2022-02-10 13:19:33.039456: W tensorflow/core/framework/dataset.cc:744] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(pid=5224)\u001b[0m \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r158/158 [==============================] - 955s 6s/step - loss: 0.1971 - accuracy: 0.9560 - precision: 0.9560 - recall: 0.9560 - prc: 0.9839 - val_loss: 0.1590 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000 - val_prc: 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluación del modelo"
      ],
      "metadata": {
        "id": "_jxKdztDO3Wq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Una vez el Estimador ha entrenado correctamente, lo evaluamos cargando los datos de evaluación llamando a su función correspondiente"
      ],
      "metadata": {
        "id": "vTr6JgmkLFzG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "stats = est.evaluate(test_data_creator, \n",
        "                     batch_size = batch_size)\n",
        "\n",
        "print(stats)"
      ],
      "metadata": {
        "id": "e2RQlaZNMdD8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "052ab836-be2b-4ba3-8899-ef41ea2f9aac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(pid=5224)\u001b[0m Found 586 images belonging to 2 classes.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(pid=5224)\u001b[0m 2022-02-10 13:35:32.274057: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:766] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_2\"\n",
            "\u001b[2m\u001b[36m(pid=5224)\u001b[0m op: \"FlatMapDataset\"\n",
            "\u001b[2m\u001b[36m(pid=5224)\u001b[0m input: \"TensorDataset/_1\"\n",
            "\u001b[2m\u001b[36m(pid=5224)\u001b[0m attr {\n",
            "\u001b[2m\u001b[36m(pid=5224)\u001b[0m   key: \"Targuments\"\n",
            "\u001b[2m\u001b[36m(pid=5224)\u001b[0m   value {\n",
            "\u001b[2m\u001b[36m(pid=5224)\u001b[0m     list {\n",
            "\u001b[2m\u001b[36m(pid=5224)\u001b[0m     }\n",
            "\u001b[2m\u001b[36m(pid=5224)\u001b[0m   }\n",
            "\u001b[2m\u001b[36m(pid=5224)\u001b[0m }\n",
            "\u001b[2m\u001b[36m(pid=5224)\u001b[0m attr {\n",
            "\u001b[2m\u001b[36m(pid=5224)\u001b[0m   key: \"_cardinality\"\n",
            "\u001b[2m\u001b[36m(pid=5224)\u001b[0m   value {\n",
            "\u001b[2m\u001b[36m(pid=5224)\u001b[0m     i: -2\n",
            "\u001b[2m\u001b[36m(pid=5224)\u001b[0m   }\n",
            "\u001b[2m\u001b[36m(pid=5224)\u001b[0m }\n",
            "\u001b[2m\u001b[36m(pid=5224)\u001b[0m attr {\n",
            "\u001b[2m\u001b[36m(pid=5224)\u001b[0m   key: \"f\"\n",
            "\u001b[2m\u001b[36m(pid=5224)\u001b[0m   value {\n",
            "\u001b[2m\u001b[36m(pid=5224)\u001b[0m     func {\n",
            "\u001b[2m\u001b[36m(pid=5224)\u001b[0m       name: \"__inference_Dataset_flat_map_flat_map_fn_7861\"\n",
            "\u001b[2m\u001b[36m(pid=5224)\u001b[0m     }\n",
            "\u001b[2m\u001b[36m(pid=5224)\u001b[0m   }\n",
            "\u001b[2m\u001b[36m(pid=5224)\u001b[0m }\n",
            "\u001b[2m\u001b[36m(pid=5224)\u001b[0m attr {\n",
            "\u001b[2m\u001b[36m(pid=5224)\u001b[0m   key: \"metadata\"\n",
            "\u001b[2m\u001b[36m(pid=5224)\u001b[0m   value {\n",
            "\u001b[2m\u001b[36m(pid=5224)\u001b[0m     s: \"\\n\\021FlatMapDataset:95\"\n",
            "\u001b[2m\u001b[36m(pid=5224)\u001b[0m   }\n",
            "\u001b[2m\u001b[36m(pid=5224)\u001b[0m }\n",
            "\u001b[2m\u001b[36m(pid=5224)\u001b[0m attr {\n",
            "\u001b[2m\u001b[36m(pid=5224)\u001b[0m   key: \"output_shapes\"\n",
            "\u001b[2m\u001b[36m(pid=5224)\u001b[0m   value {\n",
            "\u001b[2m\u001b[36m(pid=5224)\u001b[0m     list {\n",
            "\u001b[2m\u001b[36m(pid=5224)\u001b[0m       shape {\n",
            "\u001b[2m\u001b[36m(pid=5224)\u001b[0m         dim {\n",
            "\u001b[2m\u001b[36m(pid=5224)\u001b[0m           size: -1\n",
            "\u001b[2m\u001b[36m(pid=5224)\u001b[0m         }\n",
            "\u001b[2m\u001b[36m(pid=5224)\u001b[0m         dim {\n",
            "\u001b[2m\u001b[36m(pid=5224)\u001b[0m           size: -1\n",
            "\u001b[2m\u001b[36m(pid=5224)\u001b[0m         }\n",
            "\u001b[2m\u001b[36m(pid=5224)\u001b[0m         dim {\n",
            "\u001b[2m\u001b[36m(pid=5224)\u001b[0m           size: -1\n",
            "\u001b[2m\u001b[36m(pid=5224)\u001b[0m         }\n",
            "\u001b[2m\u001b[36m(pid=5224)\u001b[0m         dim {\n",
            "\u001b[2m\u001b[36m(pid=5224)\u001b[0m           size: -1\n",
            "\u001b[2m\u001b[36m(pid=5224)\u001b[0m         }\n",
            "\u001b[2m\u001b[36m(pid=5224)\u001b[0m       }\n",
            "\u001b[2m\u001b[36m(pid=5224)\u001b[0m       shape {\n",
            "\u001b[2m\u001b[36m(pid=5224)\u001b[0m         dim {\n",
            "\u001b[2m\u001b[36m(pid=5224)\u001b[0m           size: -1\n",
            "\u001b[2m\u001b[36m(pid=5224)\u001b[0m         }\n",
            "\u001b[2m\u001b[36m(pid=5224)\u001b[0m         dim {\n",
            "\u001b[2m\u001b[36m(pid=5224)\u001b[0m           size: -1\n",
            "\u001b[2m\u001b[36m(pid=5224)\u001b[0m         }\n",
            "\u001b[2m\u001b[36m(pid=5224)\u001b[0m       }\n",
            "\u001b[2m\u001b[36m(pid=5224)\u001b[0m     }\n",
            "\u001b[2m\u001b[36m(pid=5224)\u001b[0m   }\n",
            "\u001b[2m\u001b[36m(pid=5224)\u001b[0m }\n",
            "\u001b[2m\u001b[36m(pid=5224)\u001b[0m attr {\n",
            "\u001b[2m\u001b[36m(pid=5224)\u001b[0m   key: \"output_types\"\n",
            "\u001b[2m\u001b[36m(pid=5224)\u001b[0m   value {\n",
            "\u001b[2m\u001b[36m(pid=5224)\u001b[0m     list {\n",
            "\u001b[2m\u001b[36m(pid=5224)\u001b[0m       type: DT_FLOAT\n",
            "\u001b[2m\u001b[36m(pid=5224)\u001b[0m       type: DT_FLOAT\n",
            "\u001b[2m\u001b[36m(pid=5224)\u001b[0m     }\n",
            "\u001b[2m\u001b[36m(pid=5224)\u001b[0m   }\n",
            "\u001b[2m\u001b[36m(pid=5224)\u001b[0m }\n",
            "\u001b[2m\u001b[36m(pid=5224)\u001b[0m . Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n",
            "\u001b[2m\u001b[36m(pid=5224)\u001b[0m 2022-02-10 13:35:32.333619: W tensorflow/core/framework/dataset.cc:744] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 1/19 [>.............................] - ETA: 40s - loss: 0.4005 - accuracy: 0.8438 - precision: 0.8438 - recall: 0.8438 - prc: 0.9261\n",
            " 2/19 [==>...........................] - ETA: 22s - loss: 0.6308 - accuracy: 0.7812 - precision: 0.7812 - recall: 0.7812 - prc: 0.8775\n",
            " 3/19 [===>..........................] - ETA: 21s - loss: 0.5747 - accuracy: 0.8021 - precision: 0.8021 - recall: 0.8021 - prc: 0.8725\n",
            " 4/19 [=====>........................] - ETA: 19s - loss: 0.6951 - accuracy: 0.7891 - precision: 0.7891 - recall: 0.7891 - prc: 0.8401\n",
            " 5/19 [======>.......................] - ETA: 18s - loss: 0.6558 - accuracy: 0.8125 - precision: 0.8125 - recall: 0.8125 - prc: 0.8565\n",
            " 6/19 [========>.....................] - ETA: 18s - loss: 0.6960 - accuracy: 0.7917 - precision: 0.7917 - recall: 0.7917 - prc: 0.8447\n",
            " 7/19 [==========>...................] - ETA: 18s - loss: 0.7128 - accuracy: 0.7857 - precision: 0.7857 - recall: 0.7857 - prc: 0.8352\n",
            " 8/19 [===========>..................] - ETA: 16s - loss: 0.6565 - accuracy: 0.8047 - precision: 0.8047 - recall: 0.8047 - prc: 0.8554\n",
            " 9/19 [=============>................] - ETA: 14s - loss: 0.6600 - accuracy: 0.7986 - precision: 0.7986 - recall: 0.7986 - prc: 0.8520\n",
            "10/19 [==============>...............] - ETA: 13s - loss: 0.7036 - accuracy: 0.7844 - precision: 0.7844 - recall: 0.7844 - prc: 0.8387\n",
            "11/19 [================>.............] - ETA: 11s - loss: 0.7218 - accuracy: 0.7812 - precision: 0.7812 - recall: 0.7812 - prc: 0.8344\n",
            "12/19 [=================>............] - ETA: 10s - loss: 0.7329 - accuracy: 0.7786 - precision: 0.7786 - recall: 0.7786 - prc: 0.8330\n",
            "13/19 [===================>..........] - ETA: 8s - loss: 0.7467 - accuracy: 0.7764 - precision: 0.7764 - recall: 0.7764 - prc: 0.8270 \n",
            "14/19 [=====================>........] - ETA: 7s - loss: 0.7525 - accuracy: 0.7746 - precision: 0.7746 - recall: 0.7746 - prc: 0.8271\n",
            "15/19 [======================>.......] - ETA: 5s - loss: 0.7366 - accuracy: 0.7750 - precision: 0.7750 - recall: 0.7750 - prc: 0.8318\n",
            "16/19 [========================>.....] - ETA: 4s - loss: 0.7157 - accuracy: 0.7832 - precision: 0.7832 - recall: 0.7832 - prc: 0.8409\n",
            "17/19 [=========================>....] - ETA: 2s - loss: 0.7066 - accuracy: 0.7831 - precision: 0.7831 - recall: 0.7831 - prc: 0.8438\n",
            "18/19 [===========================>..] - ETA: 1s - loss: 0.7070 - accuracy: 0.7812 - precision: 0.7812 - recall: 0.7812 - prc: 0.8451\n",
            "19/19 [==============================] - 26s 1s/step - loss: 0.7189 - accuracy: 0.7799 - precision: 0.7799 - recall: 0.7799 - prc: 0.8432\n",
            "{'validation_loss': 0.7188912630081177, 'validation_accuracy': 0.7798634767532349, 'validation_precision': 0.7798634767532349, 'validation_recall': 0.7798634767532349, 'validation_prc': 0.8432269096374512}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mejoramos la visualización de las métricas obtenidas tras la evaluación"
      ],
      "metadata": {
        "id": "uIGUya_0LbYc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for stat, value in stats.items():\n",
        "  print (stat, \"\\t\", value, sep = \"\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7LH5Jg0M2I0U",
        "outputId": "7a080639-0758-4ddf-b0be-d4d1c0d1a23b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "validation_loss\t0.7188912630081177\n",
            "validation_accuracy\t0.7798634767532349\n",
            "validation_precision\t0.7798634767532349\n",
            "validation_recall\t0.7798634767532349\n",
            "validation_prc\t0.8432269096374512\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Conseguimos finalmente un 'accuracy' del 78%, lo que nos da una visión global de la calidad de la clasificación.\n",
        "\n",
        "De forma más específica, los resultados de 'precision' y 'recall' nos muestran que se producen el mismo número de errores en la clasificación de falsos negativos como de falsos positivos.\n",
        "\n",
        "Por último, el resultado de 'Precision-Recall curve' es de 0'84, un valor superior al umbral de 0'5 para considerar válido el modelo.\n",
        "\n",
        "Consideramos que este resultado es suficientemente alto para utilizar el modelo como una primera aproximación al diagnóstico de neumonía, pero siempre con la supervisión de un profesional.\n",
        "\n"
      ],
      "metadata": {
        "id": "aU1RT4YKL96P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Guardado del modelo"
      ],
      "metadata": {
        "id": "Zzmjzbe3O6gr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Guardamos el modelo entrenado para poder usarlo en el futuro"
      ],
      "metadata": {
        "id": "ANHph6zZLjfi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_path = \"/content/drive/MyDrive/MBC/Big_Data_Engineering/Big_Data_Final_Project/\"\n",
        "est.save(os.path.join(model_path, \"big_data_final_model_1\"))\n",
        "# est.shutdown()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "9ukjpdTimvZd",
        "outputId": "ac1d118e-475e-40e4-d7c3-146e481789b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/drive/MyDrive/MBC/Big_Data_Engineering/Big_Data_Final_Project/big_data_final_model_1'"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Comentarios finales"
      ],
      "metadata": {
        "id": "ggGD2wRUO96z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Como hemos visto a lo largo del código, hemos utilizado datos en grandes cantidades para generar un modelo que pueda predecir con relativamente alta precisión (78%) si una radiografía corresponde a un paciente con neumonía o no.\n",
        "\n",
        "Con la idea de explorar más opciones, nos planteamos realizar más transformaciones a las imágenes de entrenamiento, como se muestra en el código a continuación, con el fin de introducir más variabilidad en el modelo. Sin embargo, las métricas de los resultados (precisión del 72%) no mejoraban las del modelo final expuesto. Además, consideramos que tampoco se genera tanta variabilidad en el entorno en el que se consiguen las imágenes, ya que la toma de radiografías de pecho es un proceso bastante estandarizado y no suele tener variaciones de brillo o ángulo."
      ],
      "metadata": {
        "id": "PgH-yBd8O_cL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#datagen_train = ImageDataGenerator(rescale=1./255, \n",
        "#                                   horizontal_flip=True,\n",
        "#                                   rotation_range=15,\n",
        "#                                   brightness_range=[0.5,1.0],\n",
        "#                                   zoom_range=[0.9,1.0])"
      ],
      "metadata": {
        "id": "JgTTuc0_PoHO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}